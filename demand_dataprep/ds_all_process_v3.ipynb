{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tunahan.aktas\\Anaconda3\\lib\\site-packages\\mpl_toolkits\\mplot3d\\__init__.py:1: MatplotlibDeprecationWarning: \n",
      "The deprecated function was deprecated in Matplotlib 3.4 and will be removed two minor releases later.\n",
      "  from .axes3d import Axes3D\n"
     ]
    }
   ],
   "source": [
    "# Prior libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "\n",
    "# To Get Combinatiobs\n",
    "import itertools\n",
    "\n",
    "# Datetime Libraries\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "import time\n",
    "\n",
    "# Trend Seasonality\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SAS Connection Library\n",
    "import swat\n",
    "\n",
    "# In Order To Read Config File\n",
    "import json\n",
    "\n",
    "# Model Preprocess Librarires\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "# Machine Learning Algorithm Libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Other Libraries\n",
    "import math\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import cx_Oracle \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import multiprocess as mp\n",
    "from functools import partial\n",
    "\n",
    "# Database Libraries\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max.columns\", 100)\n",
    "pd.set_option(\"display.max.rows\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../config.json\", \"r\")\n",
    "params_ = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name_dict = {\n",
    "    \n",
    "    1: \"ocak\",\n",
    "    2: \"subat\",\n",
    "    3: \"mart\",\n",
    "    4: \"nisan\",\n",
    "    5: \"mayis\",\n",
    "    6: \"haziran\",\n",
    "    7: \"temmuz\",\n",
    "    8: \"agustos\",\n",
    "    9: \"eylul\",\n",
    "    10: \"ekim\",\n",
    "    11: \"kasim\",\n",
    "    12: \"aralik\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" Create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_table(df_name, database_name, table_name):\n",
    "    \"\"\"\n",
    "    Create new table into given database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_name : DataFrame\n",
    "        The DataFrame in order to create as a new table in the database.\n",
    "    \n",
    "    database_name : str\n",
    "        Specify the name of the Database that you want to create a new table from a DataFrame.\n",
    "    \n",
    "    table_name : str\n",
    "        Specify the name of the table that will be created into the database.\n",
    "        \n",
    "    \"\"\"\n",
    "    access_ = True\n",
    "    os.chdir(\"../data/db/\")\n",
    "    database_name += \".sqlite\"\n",
    "    while access_:\n",
    "        if database_name in os.listdir():\n",
    "            access_ = False\n",
    "            try:\n",
    "                conn = sqlite3.connect(database_name)\n",
    "                df_name.to_sql(table_name, conn, index=False)\n",
    "                print(f\"Table '{table_name}' is created into '{database_name}' database.\")\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(\"The provided database name is incorrect. Please check again 'database_name' parameter.\")\n",
    "            break\n",
    "    conn.close()\n",
    "    os.chdir(\"../../\"+\"data prep/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_new_results(new_results, database_name, table_name):\n",
    "    \"\"\"\n",
    "    Update a table in given database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    new_results : DataFrame\n",
    "        The DataFrame in order to upload new results into given database.\n",
    "    \n",
    "    database_name : str\n",
    "        Specify the name of the Database that you want to create a new table from a DataFrame.\n",
    "    \n",
    "    table_name : str\n",
    "        Specify the name of the table that will be created into the database.\n",
    "        \n",
    "    \"\"\"\n",
    "    os.chdir(\"../data/db/\")\n",
    "    conn = sqlite3.connect(database_name + \".sqlite\")\n",
    "    cursor = conn.cursor()\n",
    "    sql_query = f\"DROP TABLE IF EXISTS {table_name}\"\n",
    "    cursor.execute(sql_query)\n",
    "    print(\"Previous results are dropped.\")\n",
    "    os.chdir(\"../../\"+\"data prep/\")\n",
    "    conn.close()\n",
    "    create_new_table(new_results, database_name, table_name)\n",
    "    print(\"New results are uploaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_table(dataframe_to_append, database_name, table_name):\n",
    "    \"\"\"\n",
    "    Update a table in given database.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe_to_append : DataFrame\n",
    "        The DataFrame in order to upload new results into backup table which contains previous predictions.\n",
    "    \n",
    "    database_name : str\n",
    "        Specify the name of the Database that you want to create a new table from a DataFrame.\n",
    "    \n",
    "    table_name : str\n",
    "        Specify the name of the table that will be created into the database.\n",
    "        \n",
    "    \"\"\"\n",
    "    os.chdir(\"../data/db/\")\n",
    "    conn = sqlite3.connect(database_name + \".sqlite\")\n",
    "    dataframe_to_append.to_sql(table_name, con=conn, if_exists='append', index=False)\n",
    "    print(f\"New data is inserted into {table_name} table.\")\n",
    "    os.chdir(\"../../\"+\"data prep/\")\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_all_process = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Excel Files\n",
    "pas_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"pasifik_satis_path\"]) if doc_.startswith(\"Siparişe_göre_Sales_History\")])\n",
    "hor_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"horizon_satis_path\"]) if doc_.startswith(\"Horizon_Saha_\")])\n",
    "btt_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"btt_satis_path\"]) if doc_.startswith(\"Demand Sensing Sales History\") or doc_.startswith(\"Demand_Sensing_Sales_\")])\n",
    "\n",
    "saha_aktivite_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"horizon_aktivite_path\"]) if doc_.startswith(\"Demand_Sensing_Saha_Aktivit\") or doc_.startswith(\"Demand Sensing Saha Aktivit\")])\n",
    "pasifik_aktivite_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"pasifik_aktivite_path\"]) if doc_.startswith(\"Pasifik Aktivite Datası\")])\n",
    "\n",
    "portfoy_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"portfoy_path\"]) if doc_.startswith(\"Portföy\")])\n",
    "eslenik_kod_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"eslenik_kod_path\"]) if doc_.startswith(\"Ürün Eşlenik kodlar\")])\n",
    "kapsam_listeli = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"kapsam_path\"]) if doc_.startswith(\"Listeli Ürün\")])\n",
    "pas_siparis_lst = sorted([doc_ for doc_ in os.listdir(params_[\"path\"][\"pasifik_siparis_path\"]) if doc_.startswith(\"Siparişe_göre_Sales_History\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dosya Listelerini Okuma İşlemi: 0:00:00.036999\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dosya Listelerini Okuma İşlemi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chng_cols_beginning = {'Year': 'Yıl', 'Quarter': 'Çeyrek', 'Month': 'Ay', \n",
    "                       'Company Code': 'Şirket Kodu', 'Main Category Name': 'Ana Kategori Adı', \n",
    "                       'Category Name': 'Kategori Adı', 'Brand Name': 'Marka Adı', 'Product Code': 'Ürün Kodu', \n",
    "                       'Product Name': 'Ürün Adı', \"Ürün Adı (Mobis)\": 'Ürün Adı'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pas(paths_pas, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_pas+loop_list, sheet_name=\"Ürün Bazlı\", usecols=\"B:O\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hor(paths_hor, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_hor+loop_list, skiprows=1, sheet_name=\"Horizon Saha Satış\", usecols=\"B:L\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_btt(paths_btt, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_btt+loop_list, skiprows=1, sheet_name=\"BTT SAP Satış\", usecols=\"B:N\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = []\n",
    "horizon_saha_df_all = []\n",
    "btt_df_all = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    \n",
    "    paths_pas = params_[\"path\"][\"pasifik_satis_path\"]\n",
    "    paths_hor = params_[\"path\"][\"horizon_satis_path\"]\n",
    "    paths_btt = params_[\"path\"][\"btt_satis_path\"]\n",
    "\n",
    "    new_col_names = chng_cols_beginning\n",
    "\n",
    "    loop_pas = pas_lst\n",
    "    loop_hor = hor_lst\n",
    "    loop_btt = btt_lst\n",
    "    \n",
    "    func_pas = partial(read_pas, paths_pas, new_col_names)\n",
    "    func_hor = partial(read_hor, paths_hor, new_col_names)\n",
    "    func_btt = partial(read_btt, paths_btt, new_col_names)\n",
    "    \n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        pasifik_df_all.append(p.map(func_pas, loop_pas))\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        horizon_saha_df_all.append(p.map(func_hor, loop_hor))\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        btt_df_all.append(p.map(func_btt, loop_btt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataların yüklenmesi: 0:02:25.825284\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dataların yüklenmesi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = pd.concat(pasifik_df_all[0], ignore_index=True)\n",
    "horizon_saha_df_all = pd.concat(horizon_saha_df_all[0], ignore_index=True)\n",
    "btt_df_all = pd.concat(btt_df_all[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Read Data Koli İçi Adet\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chng_cols_beginning = {'Year': 'Yıl', 'Quarter': 'Çeyrek', 'Month': 'Ay', \n",
    "                       'Company Code': 'Şirket Kodu', 'Main Category Name': 'Ana Kategori Adı', \n",
    "                       'Category Name': 'Kategori Adı', 'Brand Name': 'Marka Adı', 'Product Code': 'Ürün Kodu', \n",
    "                       'Product Name': 'Ürün Adı', \"Ürün Adı (Mobis)\": 'Ürün Adı'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pas_koli_ici_adet(paths_pas, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_pas+loop_list, sheet_name=\"Koli içi adet\", skiprows=1, usecols=\"C:D\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hor_koli_ici_adet(paths_btt, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_btt+loop_list, skiprows=1, sheet_name=\"Horizon Saha Satış\", usecols=\"B,D,E,I,K\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_btt_koli_ici_adet(paths_btt, new_col_names, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_btt+loop_list, skiprows=1, sheet_name=\"BTT SAP Satış\", usecols=\"B,D,I,K\").rename(columns=new_col_names)\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet = []\n",
    "horizon_koli_ici_adet = []\n",
    "btt_koli_ici_adet = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    \n",
    "    paths_pas = params_[\"path\"][\"pasifik_satis_path\"]\n",
    "    paths_btt = params_[\"path\"][\"btt_satis_path\"]\n",
    "\n",
    "    new_col_names = chng_cols_beginning\n",
    "\n",
    "    loop_pas = [loop_pas[-1]]\n",
    "    loop_btt = btt_lst\n",
    "    \n",
    "    func_pas = partial(read_pas_koli_ici_adet, paths_pas, new_col_names)\n",
    "    func_hor = partial(read_hor_koli_ici_adet, paths_btt, new_col_names)\n",
    "    func_btt = partial(read_btt_koli_ici_adet, paths_btt, new_col_names)\n",
    "    \n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        pasifik_koli_ici_adet.append(p.map(func_pas, loop_pas))\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        horizon_koli_ici_adet.append(p.map(func_hor, loop_btt))\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        btt_koli_ici_adet.append(p.map(func_btt, loop_btt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataların yüklenmesi: 0:01:09.296317\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dataların yüklenmesi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case = list(string.ascii_lowercase)\n",
    "upper_case = list(string.ascii_uppercase)\n",
    "lower_upper_case = upper_case + lower_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet = pd.concat(pasifik_koli_ici_adet[0])\n",
    "horizon_koli_ici_adet = pd.concat(horizon_koli_ici_adet[0])\n",
    "btt_koli_ici_adet = pd.concat(btt_koli_ici_adet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet_backup = pasifik_koli_ici_adet.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltrs = list(string.ascii_letters) # Alfabede bulunan tüm harfleri tutan liste. Bunu, koli içi adet dataframe'deki harf içeren ürün kodlarını elemek için tutuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet.rename(columns={\"Ürün Kodu.1\": \"en_guncel_kod\", \"Koli İçi Adet\": \"koli_ici_adet\"}, inplace=True)\n",
    "pasifik_koli_ici_adet = pasifik_koli_ici_adet[~(pasifik_koli_ici_adet[\"en_guncel_kod\"].str.contains(\"|\".join(ltrs), regex=True))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet.en_guncel_kod = pasifik_koli_ici_adet.en_guncel_kod.apply(lambda x: int(x.replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_koli_ici_adet.rename(columns={\"Yıl\": \"yil\", \"Ay\": \"ay\", \"Saha Müşteri Grup\": \"grup_adi\", \"Ürün Kodu\": \"en_guncel_kod\", \"Koli İçi Adet\": \"koli_ici_adet\"}, inplace=True)\n",
    "btt_koli_ici_adet.rename(columns={\"Yıl\": \"yil\", \"Ay\": \"ay\", \"Saha Müşteri Grup\": \"grup_adi\", \"Ürün Kodu\": \"en_guncel_kod\", \"Koli İçi Adet\": \"koli_ici_adet\"}, inplace=True)\n",
    "btt_koli_ici_adet[\"grup_adi\"] = \"BTT\"\n",
    "btt_koli_ici_adet = btt_koli_ici_adet[horizon_koli_ici_adet.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_koli_ici_adet[\"tarih\"] = horizon_koli_ici_adet[\"yil\"].astype(str) + \"-\" + horizon_koli_ici_adet[\"ay\"].astype(str) + \"-01\"\n",
    "btt_koli_ici_adet[\"tarih\"] = btt_koli_ici_adet[\"yil\"].astype(str) + \"-\" + btt_koli_ici_adet[\"ay\"].astype(str) + \"-01\"\n",
    "\n",
    "horizon_koli_ici_adet[\"tarih\"] = pd.to_datetime(horizon_koli_ici_adet[\"tarih\"])\n",
    "btt_koli_ici_adet[\"tarih\"] = pd.to_datetime(btt_koli_ici_adet[\"tarih\"])\n",
    "\n",
    "horizon_koli_ici_adet.drop(columns=[\"yil\", \"ay\"], axis=1, inplace=True)\n",
    "btt_koli_ici_adet.drop(columns=[\"yil\", \"ay\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_koli_ici_adet.grup_adi = horizon_koli_ici_adet.grup_adi.apply(lambda x: \"Diğer_Horizon\" if x == \"Diğer\" else x)\n",
    "pasifik_koli_ici_adet.drop_duplicates(\"en_guncel_kod\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet2 = []\n",
    "for grup_adii in [\"A101\", \"BİM\", \"Diğer_Pasifik\", \"ŞOK\", \"MİGROS\"]:\n",
    "    tmp = pasifik_koli_ici_adet.copy()\n",
    "    tmp[\"grup_adi\"] = grup_adii\n",
    "    tmp[\"tarih\"] = datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)\n",
    "    pasifik_koli_ici_adet2.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet2 = pd.concat(pasifik_koli_ici_adet2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_koli_ici_adet2 = pasifik_koli_ici_adet2[horizon_koli_ici_adet.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_all = pd.concat([pasifik_koli_ici_adet2, horizon_koli_ici_adet, btt_koli_ici_adet], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sadece Gerekli Sütunlar Tutuluyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all.drop(columns=[\"Organizasyon Kodu\", \"Grup Kodu.\", \"Pladis-Non Pladis\"], axis=1, inplace=True)\n",
    "horizon_saha_df_all.drop(columns=[\"Çeyrek\"], axis=1, inplace=True)\n",
    "btt_df_all.drop(columns=[\"Çeyrek\", \"Şirket Kodu\"], axis=1, inplace=True)\n",
    "\n",
    "btt_df_all[\"Grup Adı\"] = \"BTT\"\n",
    "pasifik_df_all.rename(columns={\"Ana Kategori\": \"Ana Kategori Adı\", \"Kategori\": \"Kategori Adı\", \"Ürün Adı (Orjinal)\": \"Ürün Adı\", \"Sipariş Miktarı(Dönüş. Koli)\": \"Koli\", \n",
    "                               \"Sipariş Brüt Tutar\": \"KG\", \"Sipariş Brüt KG\": \"TL\"}, inplace=True)\n",
    "\n",
    "horizon_saha_df_all.rename(columns={\"Horizon müşteri grup\": \"Grup Adı\", \"Ürün Adı (Orjinal)\": \"Ürün Adı\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_all.dropna(inplace=True, how=\"any\")\n",
    "horizon_saha_df_all.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasifik Kısmı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['Yıl', 'Ay', 'Grup Adı', 'Ana Kategori Adı', 'Kategori Adı', 'Marka Adı', 'Ürün Kodu', 'Ürün Adı', 'Koli', 'KG', 'TL']\n",
    "ltrs = list(string.ascii_letters) # Alfabede bulunan tüm harfleri tutan liste. Bunu, koli içi adet dataframe'deki harf içeren ürün kodlarını elemek için tutuyoruz.\n",
    "\n",
    "horizon_saha_df_all[\"Kategori Adı\"] = np.nan\n",
    "\n",
    "pasifik_df_all = pasifik_df_all[col_order]\n",
    "horizon_saha_df_all = horizon_saha_df_all[col_order]\n",
    "btt_df_all = btt_df_all[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aktivite_detay(paths_detay, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_detay+loop_list, skiprows=1, sheet_name=\"Ürün Detay\", usecols=\"B:M\")\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_aktivite_cat(paths_cat, loop_list):\n",
    "    import pandas as pd\n",
    "    print(\"Okumaya başladı.\", loop_list)\n",
    "    new_df = pd.read_excel(paths_cat+loop_list, skiprows=1, sheet_name=\"Kategori\", usecols=\"B:I\")\n",
    "    print(\"Okuma bitti ---->\", loop_list)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay = []\n",
    "#saha_aktivite_cat = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    \n",
    "    paths_detay = params_[\"path\"][\"horizon_aktivite_path\"]\n",
    "#    paths_cat = params_[\"path\"][\"horizon_aktivite_path\"]\n",
    "\n",
    "    loop_detay = saha_aktivite_lst\n",
    "#    loop_cat = saha_aktivite_lst\n",
    "    \n",
    "    func_detay = partial(read_aktivite_detay, paths_detay)\n",
    "#    func_cat = partial(read_aktivite_cat, paths_cat)\n",
    "    \n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        saha_aktivite_detay.append(p.map(func_detay, loop_detay))\n",
    "#    with mp.Pool(available_cpu) as p:\n",
    "#        saha_aktivite_cat.append(p.map(func_cat, loop_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataların yüklenmesi: 0:00:16.318386\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dataların yüklenmesi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay = pd.concat(saha_aktivite_detay[0], ignore_index=True)\n",
    "#saha_aktivite_cat = pd.concat(saha_aktivite_cat[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay.drop_duplicates(subset=[\"Yıl\", \"Ay\", \"Saha Müşteri Grup\", \"Ürün Kodu\"], keep=\"first\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Pasifik Aktiviteleri\n",
    "pasifik_aktivite_df = pd.read_excel(params_[\"path\"][\"pasifik_aktivite_path\"]+pasifik_aktivite_lst[0])\n",
    "pasifik_aktivite_df.drop_duplicates(subset=[\"Yıl\", \"Ay\", \"Müşteri Grup\", \"Ürün Kodu\"], keep=\"first\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Fiyat Listesi\n",
    "fiyat_lst_pasifik = pd.read_excel(params_[\"path\"][\"fiyat_listesi_path\"]+params_[\"files\"][\"pasifik_fiyat_file\"])\n",
    "fiyat_lst_horizon = pd.read_excel(params_[\"path\"][\"fiyat_listesi_path\"]+params_[\"files\"][\"horizon_fiyat_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Portföy\n",
    "pasifik_portfoy_df = pd.read_excel(params_[\"path\"][\"portfoy_path\"]+portfoy_lst[0], sheet_name=\"Pasifik Portföy\", skiprows=3, usecols=\"D:H\")\n",
    "btt_portfoy_df = pd.read_excel(params_[\"path\"][\"portfoy_path\"]+portfoy_lst[0], sheet_name=\"BTT Portföy\", skiprows=2, usecols=\"D:H\")\n",
    "horizon_portfoy_df = pd.read_excel(params_[\"path\"][\"portfoy_path\"]+portfoy_lst[0], sheet_name=\"Horizon Portföy\", skiprows=2, usecols=\"E:I\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Eşlenik Kodları\n",
    "eslenik_kod_df = pd.read_excel(params_[\"path\"][\"eslenik_kod_path\"]+eslenik_kod_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Calender\n",
    "calender_df = pd.read_excel(params_[\"path\"][\"calender_path\"]+params_[\"files\"][\"calender_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eslenik_kod_df[\"En Güncel Kod\"] = eslenik_kod_df[\"En Güncel Kod\"].apply(lambda x: int(x) if x not in ['delist ', \"delist\", \"Delist\"] else x.replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a101_kapsam = pd.read_excel(params_[\"path\"][\"kapsam_path\"]+kapsam_listeli[0], sheet_name=\"A101 Portföy\")\n",
    "sok_kapsam = pd.read_excel(params_[\"path\"][\"kapsam_path\"]+kapsam_listeli[0], sheet_name=\"Şok Portföy\")\n",
    "bim_kapsam = pd.read_excel(params_[\"path\"][\"kapsam_path\"]+kapsam_listeli[0], sheet_name=\"Bim Portföy\")\n",
    "\n",
    "a101_kapsam[\"grup_adi\"] = \"A101\"\n",
    "sok_kapsam[\"grup_adi\"] = \"ŞOK\"\n",
    "bim_kapsam[\"grup_adi\"] = \"BİM\"\n",
    "\n",
    "kapsam_all = pd.concat([a101_kapsam, sok_kapsam, bim_kapsam], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Koli Birim Ağırlıkları\n",
    "koli_birim_agirlik = pd.read_excel(params_[\"files\"][\"koli_agirlik_birim_file\"])\n",
    "koli_birim_agirlik_pas = pd.read_excel(params_[\"files\"][\"koli_agirlik_birim_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_birim_agirlik.rename(columns={\"Malzeme\": \"en_guncel_kod\", \n",
    "                                   \"Malzeme Açıklaması\": \"urun_adi\", \n",
    "                                   \"Ana Kategori\": \"ana_kategori_adi\",\n",
    "                                   \"Kategori\": \"kategori_adi\",\n",
    "                                   \"Alt Kategori\": \"alt_kategori_adi\",\n",
    "                                   \"Detay Kategori\": \"detay_kategori_adi\",\n",
    "                                   \"Marka\": \"marka_adi\", \"Marka Açıklaması\": \"marka_aciklamasi\",\n",
    "                                   \"Net Ağırlık\": \"kg\"}, inplace=True)\n",
    "\n",
    "koli_birim_agirlik_pas.rename(columns={\"Malzeme\": \"en_guncel_kod\", \n",
    "                                   \"Malzeme Açıklaması\": \"urun_adi\", \n",
    "                                   \"Ana Kategori\": \"ana_kategori_adi\",\n",
    "                                   \"Kategori\": \"kategori_adi\",\n",
    "                                   \"Alt Kategori\": \"alt_kategori_adi\",\n",
    "                                   \"Detay Kategori\": \"detay_kategori_adi\",\n",
    "                                   \"Marka\": \"marka_adi\", \"Marka Açıklaması\": \"marka_aciklamasi\",\n",
    "                                   \"Net Ağırlık\": \"kg\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_birim_agirlik_pas[\"kanal\"] = \"pasifik\"\n",
    "koli_birim_agirlik_hor = koli_birim_agirlik.copy()\n",
    "koli_birim_agirlik_btt = koli_birim_agirlik.copy()\n",
    "koli_birim_agirlik_hor[\"kanal\"] = \"horizon\"\n",
    "koli_birim_agirlik_btt[\"kanal\"] = \"btt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_birim_agirlik = pd.concat([koli_birim_agirlik_pas, koli_birim_agirlik_hor, koli_birim_agirlik_btt], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diğer dataların Jupytere yüklenme süresi: 0:00:21.596053\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Diğer dataların Jupytere yüklenme süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pasifik 2016 aktivite verileri olmadığı için 2016 Sales dataları çıkartıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = pasifik_df_all[pasifik_df_all[\"Yıl\"] != 2016].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_all[\"Yıl\"] = horizon_saha_df_all[\"Yıl\"].astype(int)\n",
    "horizon_saha_df_all[\"Ay\"] = horizon_saha_df_all[\"Ay\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sales Datası İçin Ürün Kod Eşleme\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = pd.merge(pasifik_df_all, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], on=\"Ürün Kodu\", how=\"left\")\n",
    "horizon_saha_df_all = pd.merge(horizon_saha_df_all, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], on=\"Ürün Kodu\", how=\"left\")\n",
    "btt_df_all = pd.merge(btt_df_all, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], on=\"Ürün Kodu\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ürün Eşleme Kodları dosyasında yer almayan kodlar için mevcut ürün kodları verildi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ = pasifik_df_all[pd.isnull(pasifik_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "full_ = pasifik_df_all[~pd.isnull(pasifik_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "empty_[\"En Güncel Kod\"] = empty_[\"Ürün Kodu\"]\n",
    "pasifik_df_all = pd.concat([empty_, full_], axis=0, ignore_index=True)\n",
    "pasifik_df_all = pasifik_df_all.sort_values(pasifik_df_all.columns.to_list()).reset_index(drop=True)\n",
    "\n",
    "empty_ = btt_df_all[pd.isnull(btt_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "full_ = btt_df_all[~pd.isnull(btt_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "empty_[\"En Güncel Kod\"] = empty_[\"Ürün Kodu\"]\n",
    "btt_df_all = pd.concat([empty_, full_], axis=0, ignore_index=True)\n",
    "btt_df_all = btt_df_all.sort_values(btt_df_all.columns.to_list()).reset_index(drop=True)\n",
    "\n",
    "empty_ = horizon_saha_df_all[pd.isnull(horizon_saha_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "full_ = horizon_saha_df_all[~pd.isnull(horizon_saha_df_all[\"En Güncel Kod\"])].reset_index(drop=True)\n",
    "empty_[\"En Güncel Kod\"] = empty_[\"Ürün Kodu\"]\n",
    "horizon_saha_df_all = pd.concat([empty_, full_], axis=0, ignore_index=True)\n",
    "horizon_saha_df_all = horizon_saha_df_all.sort_values(horizon_saha_df_all.columns.to_list()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adet adında yeni bir kolon oluşturuldu. Koli Sayısı 100'den az olanlara 0 yazıyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all[\"Koli\"] = np.where(pasifik_df_all[\"Koli\"] < 100, 0, pasifik_df_all[\"Koli\"])\n",
    "btt_df_all[\"Koli\"] = np.where(btt_df_all[\"Koli\"] < 100, 0, btt_df_all[\"Koli\"])\n",
    "horizon_saha_df_all[\"Koli\"] = np.where(horizon_saha_df_all[\"Koli\"] < 100, 0, horizon_saha_df_all[\"Koli\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = pasifik_df_all[pasifik_df_all[\"Koli\"] != 0].reset_index(drop=True)\n",
    "btt_df_all = btt_df_all[btt_df_all[\"Koli\"] != 0].reset_index(drop=True)\n",
    "horizon_saha_df_all = horizon_saha_df_all[horizon_saha_df_all[\"Koli\"] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delist olan ürünler veriden çıkartıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all = pasifik_df_all[pasifik_df_all[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "btt_df_all = btt_df_all[btt_df_all[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "horizon_saha_df_all = horizon_saha_df_all[horizon_saha_df_all[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aynı yıl, ay, grup adı, ana kategori adı, kategori adı, marka adı ve SKU kodundaki ürünler için toplam alındı. Sadece Koli İçi Adet için maksimum olan alındı."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marka adı dahil değil groupby'a\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_to_sum = {\"Koli\": \"sum\", \"KG\": \"sum\", \"TL\": \"sum\"}\n",
    "\n",
    "pasifik_df_all2 = pasifik_df_all.groupby([\"Yıl\", \"Ay\", \"Grup Adı\", \"Ana Kategori Adı\", \"Kategori Adı\", \"En Güncel Kod\"]).agg(dct_to_sum).reset_index()\n",
    "btt_df_all2 = btt_df_all.groupby([\"Yıl\", \"Ay\", \"Grup Adı\", \"Ana Kategori Adı\", \"Kategori Adı\", \"En Güncel Kod\"]).agg(dct_to_sum).reset_index()\n",
    "horizon_saha_df_all2 = horizon_saha_df_all.groupby([\"Yıl\", \"Ay\", \"Grup Adı\", \"Ana Kategori Adı\", \"En Güncel Kod\"]).agg(dct_to_sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all2[\"Date\"] = pasifik_df_all2[\"Yıl\"].astype(str) + \"-\" +  pasifik_df_all2[\"Ay\"].astype(str) + \"-01\"\n",
    "btt_df_all2[\"Date\"] = btt_df_all2[\"Yıl\"].astype(int).astype(str) + \"-\" +  btt_df_all2[\"Ay\"].astype(int).astype(str) + \"-01\"\n",
    "horizon_saha_df_all2[\"Date\"] = horizon_saha_df_all2[\"Yıl\"].astype(int).astype(str) + \"-\" +  horizon_saha_df_all2[\"Ay\"].astype(int).astype(str) + \"-01\"\n",
    "\n",
    "pasifik_df_all2[\"Date\"] = pd.to_datetime(pasifik_df_all2[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "btt_df_all2[\"Date\"] = pd.to_datetime(btt_df_all2[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "horizon_saha_df_all2[\"Date\"] = pd.to_datetime(horizon_saha_df_all2[\"Date\"], format=\"%Y-%m-%d\", errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43165, 10), (173332, 9), (14501, 10))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasifik_df_all2.shape, horizon_saha_df_all2.shape, btt_df_all2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizon ve Pasifikte bulunan \"Diğer\"'lerin yanlarına \"_\" ile Diğer_Pasifik, Diğer_Horizon yazıldı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all2[\"Grup Adı\"] = pasifik_df_all2[\"Grup Adı\"].apply(lambda x: \"Diğer_Pasifik\" if x == \"Diğer\" else x)\n",
    "horizon_saha_df_all2[\"Grup Adı\"] = horizon_saha_df_all2[\"Grup Adı\"].apply(lambda x: \"Diğer_Horizon\" if x == \"Diğer\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all2 = pd.concat([pasifik_df_all2, horizon_saha_df_all2, btt_df_all2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params_[\"time_info_for_debugging\"][\"ay\"] == 12:\n",
    "    ay_threshold = 1 #params_[\"time_info_for_debugging\"][\"ay\"] = 1\n",
    "    yil_threshold = params_[\"time_info_for_debugging\"][\"yil\"] + 1\n",
    "else:\n",
    "    ay_threshold = params_[\"time_info_for_debugging\"][\"ay\"] + 1\n",
    "    yil_threshold = params_[\"time_info_for_debugging\"][\"yil\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pasifik_df_all2 = pasifik_df_all2[pasifik_df_all2[\"Date\"] <= datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)].reset_index(drop=True)\n",
    "horizon_saha_df_all2 = horizon_saha_df_all2[horizon_saha_df_all2[\"Date\"] <= datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)].reset_index(drop=True)\n",
    "btt_df_all2 = btt_df_all2[btt_df_all2[\"Date\"] <= datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all2 = pasifik_df_all2[pasifik_df_all2[\"Date\"] < datetime(yil_threshold, ay_threshold, 1)].reset_index(drop=True)\n",
    "horizon_saha_df_all2 = horizon_saha_df_all2[horizon_saha_df_all2[\"Date\"] < datetime(yil_threshold, ay_threshold, 1)].reset_index(drop=True)\n",
    "btt_df_all2 = btt_df_all2[btt_df_all2[\"Date\"] < datetime(yil_threshold, ay_threshold, 1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pasifik Filling Missing Dates\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_dates(df__, df_unique_list):\n",
    "    df_all_filled = []\n",
    "    for idx in df_unique_list.index:\n",
    "        tmp_df = df__[(df__[\"Grup Adı\"] == df_unique_list[\"Grup Adı\"][idx]) & (df__[\"En Güncel Kod\"] == df_unique_list[\"En Güncel Kod\"][idx])]\n",
    "        time_interval = []\n",
    "        dt = tmp_df.Date.min()\n",
    "        while dt <= datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1):\n",
    "            time_interval.append(dt)\n",
    "            dt += relativedelta(months=1)\n",
    "        date_to_add = [i for i in time_interval if i not in tmp_df.Date.unique()]\n",
    "        if len(date_to_add) > 0:\n",
    "            add_df = pd.concat([pd.DataFrame(tmp_df.iloc[0]).T]*len(date_to_add))\n",
    "            add_df[\"Koli\"], add_df[\"KG\"], add_df[\"TL\"] = 0, 0, 0\n",
    "            add_df[\"Date\"] = date_to_add\n",
    "            add_df[\"Yıl\"] = add_df[\"Date\"].dt.year\n",
    "            add_df[\"Ay\"] = add_df[\"Date\"].dt.month\n",
    "            df_all_filled.append(pd.concat([tmp_df, add_df], ignore_index=True))\n",
    "        else: \n",
    "            df_all_filled.append(tmp_df)\n",
    "    return pd.concat(df_all_filled, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = pasifik_df_all2.drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\"], ignore_index=True)[[\"Grup Adı\", \"En Güncel Kod\"]]\n",
    "pasifik_df_all2 = fill_missing_dates(pasifik_df_all2, unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasifik missing value düzenlenmesi süresi: 0:00:33.762857\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Pasifik missing value düzenlenmesi süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Horizon Filling Missing Values\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = horizon_saha_df_all2.drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\"], ignore_index=True)[[\"Grup Adı\", \"En Güncel Kod\"]]\n",
    "horizon_saha_df_all2 = fill_missing_dates(horizon_saha_df_all2, unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon missing value düzenlenmesi süresi: 0:05:08.159233\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Horizon missing value düzenlenmesi süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# BTT Filling Missing Values\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = btt_df_all2.drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\"], ignore_index=True)[[\"Grup Adı\", \"En Güncel Kod\"]]\n",
    "btt_df_all2 = fill_missing_dates(btt_df_all2, unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTT missing value düzenlenmesi süresi: 0:00:05.222167\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('BTT missing value düzenlenmesi süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all22 = pd.concat([pasifik_df_all2, horizon_saha_df_all2, btt_df_all2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aktivite Datası İçin Ürün Kod Eşleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasifik Aktivite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left join ile güncel kodlar getirildi. Delist olan ürünler listeden çıkartıldı. \"Çeyrek\" sütunu silindi. En güncel kod sütunnuda bulunamayan değerler Ürün Kodu sütunundan çekildi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_aktivite_df2 = pd.merge(pasifik_aktivite_df, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], on=\"Ürün Kodu\", how=\"left\")\n",
    "pasifik_aktivite_df2 = pasifik_aktivite_df2[pasifik_aktivite_df2[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "pasifik_aktivite_df2.drop(\"Çeyrek\", inplace=True, axis=1)\n",
    "pasifik_aktivite_df2['En Güncel Kod'] = pasifik_aktivite_df2['En Güncel Kod'].fillna(pasifik_aktivite_df2['Ürün Kodu'])\n",
    "pasifik_aktivite_df2.drop(columns=\"Ürün Kodu\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasifik Aktivite Ciro - Promosyon Tutarı ve İskonto Tekilleştirme (ORTALAMA ALARAK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_pas = {\"Raf Tavsiye Satış Fiyatı\": \"mean\", \"İndirimli Raf Satış Fiyatı\": \"mean\", \"İndirim %\": \"mean\", \"Aktivite Tipi\": \"first\"}\n",
    "pasifik_aktivite_df3 = pasifik_aktivite_df2.groupby([\"En Güncel Kod\", \"Yıl\", \"Ay\", \"Müşteri Grup\"]).agg(ort_pas).reset_index()\n",
    "pasifik_aktivite_df3 = pd.merge(pasifik_aktivite_df3, pasifik_aktivite_df2[[\"Yıl\", \"Ay\", \"Müşteri Grup\", \"En Güncel Kod\", \n",
    "                                                                            \"Ana Kategori Adı\", \"Kategori Adı\", \"Marka Adı\"]],\n",
    "                                how=\"left\", \n",
    "                                on=[\"En Güncel Kod\", \"Yıl\", \"Ay\", \"Müşteri Grup\"])\n",
    "\n",
    "pasifik_aktivite_df3.drop_duplicates(subset=pasifik_aktivite_df3.columns.to_list(), inplace=True)\n",
    "pasifik_aktivite_df3.reset_index(drop=True, inplace=True)\n",
    "pasifik_aktivite_df3 = pasifik_aktivite_df3[pasifik_aktivite_df2.drop(\"Ürün Adı\", axis=1).columns.to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizon Aktivite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay2 = pd.merge(saha_aktivite_detay, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], on=\"Ürün Kodu\", how=\"left\")\n",
    "saha_aktivite_detay2 = saha_aktivite_detay2[saha_aktivite_detay2[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "saha_aktivite_detay2.drop(\"Çeyrek\", inplace=True, axis=1)\n",
    "saha_aktivite_detay2['En Güncel Kod'] = saha_aktivite_detay2['En Güncel Kod'].fillna(saha_aktivite_detay2['Ürün Kodu'])\n",
    "saha_aktivite_detay2.drop(columns=\"Ürün Kodu\", axis=1, inplace=True)\n",
    "saha_aktivite_detay2[\"İskonto %\"].replace(\"#DIV/0\", np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizon Aktivite Ciro - Promosyon Tutarı ve İskonto Tekilleştirme (ORTALAMA ALARAK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort = {\"Ciro (Kull. İade Düş.)\": \"mean\", \"Promosyon Tutarı\": \"mean\", \"İskonto %\": \"mean\"}\n",
    "saha_aktivite_detay3 = saha_aktivite_detay2.groupby([\"En Güncel Kod\", \"Yıl\", \"Ay\", \"Saha Müşteri Grup\"]).agg(ort).reset_index()\n",
    "\n",
    "saha_aktivite_detay3 = pd.merge(saha_aktivite_detay3, saha_aktivite_detay2[[\"Yıl\", \"Ay\", \"Saha Müşteri Grup\", \"En Güncel Kod\", \n",
    "                                                 \"Ana Kategori Adı\", \"Kategori Adı\", \"Marka Adı\"]],\n",
    "                           how=\"left\", \n",
    "                           on=[\"En Güncel Kod\", \"Yıl\", \"Ay\", \"Saha Müşteri Grup\"])\n",
    "\n",
    "saha_aktivite_detay3.drop_duplicates(subset=saha_aktivite_detay3.columns.to_list(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay3 = saha_aktivite_detay3[saha_aktivite_detay2.drop(\"Ürün Adı (Mobis)\", axis=1).columns.to_list()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay3.rename(columns={\"Saha Müşteri Grup\": \"Grup Adı\"}, inplace=True)\n",
    "saha_aktivite_detay3[\"Grup Adı\"] = saha_aktivite_detay3[\"Grup Adı\"].apply(lambda x: \"Diğer_Horizon\" if x == \"Diğer\" else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiyat Listesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizon Fiyatları\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Fiyat Listesi\n",
    "fiyat_lst_horizon = pd.read_excel(params_[\"path\"][\"fiyat_listesi_path\"]+params_[\"files\"][\"horizon_fiyat_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_horizon.drop_duplicates(subset=fiyat_lst_horizon.columns.to_list(), keep=\"first\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fiyat_lst_horizon[\"Malzeme\"] = fiyat_lst_horizon[\"Malzeme\"].str.replace(\"-\", \"\")\n",
    "    fiyat_lst_horizon[\"Malzeme\"] = fiyat_lst_horizon[\"Malzeme\"].astype(int)*1\n",
    "except:\n",
    "    fiyat_lst_horizon[\"Malzeme\"] = fiyat_lst_horizon[\"Malzeme\"].astype(int)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_horizon_df = fiyat_lst_horizon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_horizon_df[\"Baslangic_Yıl\"] = fiyat_lst_horizon_df[\"Bşl.tarihi\"].apply(lambda x: x.year)\n",
    "fiyat_lst_horizon_df[\"Baslangic_Ay\"] = fiyat_lst_horizon_df[\"Bşl.tarihi\"].apply(lambda x: x.month)\n",
    "fiyat_lst_horizon_df[\"Baslangic_Gun\"] = fiyat_lst_horizon_df[\"Bşl.tarihi\"].apply(lambda x: x.day)\n",
    "fiyat_lst_horizon_df[\"Gecerlilik_Yıl\"] = fiyat_lst_horizon_df[\"Gçrl.sonu\"].apply(lambda x: x.year)\n",
    "fiyat_lst_horizon_df[\"Gecerlilik_Ay\"] = fiyat_lst_horizon_df[\"Gçrl.sonu\"].apply(lambda x: x.month)\n",
    "fiyat_lst_horizon_df[\"Gecerlilik_Gun\"] = fiyat_lst_horizon_df[\"Gçrl.sonu\"].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_horizon_df[\"Baslangic_Yıl\"] = fiyat_lst_horizon_df[\"Baslangic_Yıl\"].apply(lambda x: (horizon_saha_df_all2[\"Date\"].max().year)+1 if x > horizon_saha_df_all2[\"Date\"].max().year else x)\n",
    "fiyat_lst_horizon_df[\"Gecerlilik_Yıl\"] = fiyat_lst_horizon_df[\"Gecerlilik_Yıl\"].apply(lambda x: (horizon_saha_df_all2[\"Date\"].max().year)+1 if x > horizon_saha_df_all2[\"Date\"].max().year else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = horizon_saha_df_all2[\"Date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_fiyat_unique = []\n",
    "\n",
    "for malzeme in fiyat_lst_horizon_df[\"Malzeme\"].unique():\n",
    "#for malzeme in [35903]:\n",
    "    temp_time_df = pd.DataFrame({\"Fiyat\": [np.nan]}, index=time_index)\n",
    "    temp_time_df = temp_time_df.reset_index().rename(columns={\"index\":\"date\"})    \n",
    "    temp_time_df[\"En Güncel Kod\"] = malzeme\n",
    "    temp_time_df[\"fiyat_gecisi\"] = 0\n",
    "    malzeme_df = fiyat_lst_horizon_df[fiyat_lst_horizon_df[\"Malzeme\"] == malzeme].reset_index(drop=True)\n",
    "    malzeme_df.drop(columns=[\"KşTü\", \"Koşul türü\", \"Tanım\", \"Ana Kategori\", \"Kategori\", \"ÖB\"], axis=1, inplace=True)\n",
    "    malzeme_df.drop_duplicates(subset=malzeme_df.columns.to_list(), inplace=True, ignore_index=True)\n",
    "    malzeme_df.sort_values(by=[\"Baslangic_Yıl\", \"Baslangic_Ay\", \"Baslangic_Gun\"], ignore_index=True, inplace=True)\n",
    "    check_idx1 = []\n",
    "    if len(malzeme_df) > 1:\n",
    "        for row1 in malzeme_df.index:\n",
    "            for row2 in malzeme_df[row1+1:].index:\n",
    "                if (malzeme_df.loc[row1][\"Gecerlilik_Yıl\"] == malzeme_df.loc[row2][\"Baslangic_Yıl\"]) and (malzeme_df.loc[row1][\"Gecerlilik_Ay\"] == malzeme_df.loc[row2][\"Baslangic_Ay\"]):\n",
    "                    num_days = calendar.monthrange(int(malzeme_df.loc[row2][\"Baslangic_Yıl\"]), int(malzeme_df.loc[row2][\"Baslangic_Ay\"]))[1]\n",
    "                    fyt=((int(malzeme_df.loc[row1][\"Gecerlilik_Gun\"])*malzeme_df.loc[row1][\"     Tutar\"]) + (num_days - int(malzeme_df.loc[row2][\"Baslangic_Gun\"]) + 1)*malzeme_df.loc[row2][\"     Tutar\"])/num_days\n",
    "\n",
    "                    end_idx1 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx1 = temp_time_df[temp_time_df[\"date\"] == end_idx1].index\n",
    "                    temp_time_df.loc[final_idx1, \"Fiyat\"] = fyt\n",
    "                    temp_time_df.loc[final_idx1,\"fiyat_gecisi\"] = 1\n",
    "\n",
    "                elif (malzeme_df.loc[row1, \"Gecerlilik_Gun\"] == calendar.monthrange(int(malzeme_df.loc[row1][\"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1][\"Gecerlilik_Ay\"]))[1] \\\n",
    "                     and malzeme_df.loc[row2, \"Baslangic_Gun\"] == 1):\n",
    "                    fyt5=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                    fyt6=malzeme_df.loc[row2][\"     Tutar\"]\n",
    "                    end_idx5 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    end_idx6 =  datetime(int(malzeme_df.loc[row2, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row2, \"Baslangic_Ay\"]), 1)\n",
    "                    final_idx5 = temp_time_df[temp_time_df[\"date\"] == end_idx5].index\n",
    "                    final_idx6 = temp_time_df[temp_time_df[\"date\"] == end_idx6].index\n",
    "                    temp_time_df.loc[final_idx5, \"Fiyat\"] = fyt5\n",
    "                    temp_time_df.loc[final_idx6, \"Fiyat\"] = fyt6\n",
    "\n",
    "                else:\n",
    "                    fyt2=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                    start_idx2 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                    end_idx2 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx2 = temp_time_df[(temp_time_df[\"date\"] > start_idx2) & (temp_time_df[\"date\"] < end_idx2)].index\n",
    "                    temp_time_df.loc[final_idx2, \"Fiyat\"] = fyt2\n",
    "            if (row1 == len(malzeme_df)-1) or (row1 == len(malzeme_df)-2):\n",
    "                fyt3=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                start_idx3 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                end_idx3 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                final_idx3 = temp_time_df[(temp_time_df[\"date\"] > start_idx3) & (temp_time_df[\"date\"] < end_idx3)].index\n",
    "                temp_time_df.loc[final_idx3, \"Fiyat\"] = fyt3\n",
    "\n",
    "    else:\n",
    "        for row1 in malzeme_df.index:\n",
    "            fyt4=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "            start_idx4 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "            end_idx4 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "            final_idx4 = temp_time_df[(temp_time_df[\"date\"] >= start_idx4) & (temp_time_df[\"date\"] <= end_idx4)].index\n",
    "            temp_time_df.loc[final_idx4, \"Fiyat\"] = fyt4\n",
    "\n",
    "    if (malzeme_df.loc[0, \"Baslangic_Yıl\"] >= min(horizon_saha_df_all2[\"Yıl\"].unique())) and (len(malzeme_df) > 1):\n",
    "        temp_time_df.loc[temp_time_df[~pd.isnull(temp_time_df[\"Fiyat\"])].index[0]-1, \"Fiyat\"] = malzeme_df.loc[0, \"     Tutar\"]\n",
    "    temp_time_df = temp_time_df.dropna().reset_index(drop=True)\n",
    "\n",
    "    h_fiyat_unique.append(temp_time_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h_fiyat_unique = []\n",
    "\n",
    "for malzeme in fiyat_lst_horizon_df[\"Malzeme\"].unique():\n",
    "#for malzeme in [35903]:\n",
    "    temp_time_df = pd.DataFrame({\"Fiyat\": [np.nan]}, index=time_index)\n",
    "    temp_time_df = temp_time_df.reset_index().rename(columns={\"index\":\"date\"})    \n",
    "    temp_time_df[\"En Güncel Kod\"] = malzeme\n",
    "    temp_time_df[\"fiyat_gecisi\"] = 0\n",
    "    malzeme_df = fiyat_lst_horizon_df[fiyat_lst_horizon_df[\"Malzeme\"] == malzeme].reset_index(drop=True)\n",
    "    malzeme_df.drop(columns=[\"KşTü\", \"Koşul türü\", \"Tanım\", \"Ana Kategori\", \"Kategori\", \"ÖB\"], axis=1, inplace=True)\n",
    "    malzeme_df.drop_duplicates(subset=malzeme_df.columns.to_list(), inplace=True, ignore_index=True)\n",
    "    malzeme_df.sort_values(by=[\"Baslangic_Yıl\", \"Baslangic_Ay\", \"Baslangic_Gun\"], ignore_index=True, inplace=True)\n",
    "    check_idx1 = []\n",
    "    try:\n",
    "        if len(malzeme_df) > 1:\n",
    "            for row1 in malzeme_df.index:\n",
    "                for row2 in malzeme_df[row1+1:].index:\n",
    "                    if (malzeme_df.loc[row1][\"Gecerlilik_Yıl\"] == malzeme_df.loc[row2][\"Baslangic_Yıl\"]) and (malzeme_df.loc[row1][\"Gecerlilik_Ay\"] == malzeme_df.loc[row2][\"Baslangic_Ay\"]):\n",
    "                        num_days = calendar.monthrange(int(malzeme_df.loc[row2][\"Baslangic_Yıl\"]), int(malzeme_df.loc[row2][\"Baslangic_Ay\"]))[1]\n",
    "                        fyt=((int(malzeme_df.loc[row1][\"Gecerlilik_Gun\"])*malzeme_df.loc[row1][\"     Tutar\"]) + (num_days - int(malzeme_df.loc[row2][\"Baslangic_Gun\"]) + 1)*malzeme_df.loc[row2][\"     Tutar\"])/num_days\n",
    "\n",
    "                        end_idx1 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                        final_idx1 = temp_time_df[temp_time_df[\"date\"] == end_idx1].index\n",
    "                        temp_time_df.loc[final_idx1, \"Fiyat\"] = fyt\n",
    "                        temp_time_df.loc[final_idx1,\"fiyat_gecisi\"] = 1\n",
    "\n",
    "                    elif (malzeme_df.loc[row1, \"Gecerlilik_Gun\"] == calendar.monthrange(int(malzeme_df.loc[row1][\"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1][\"Gecerlilik_Ay\"]))[1] \\\n",
    "                         and malzeme_df.loc[row2, \"Baslangic_Gun\"] == 1):\n",
    "                        fyt5=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                        fyt6=malzeme_df.loc[row2][\"     Tutar\"]\n",
    "                        end_idx5 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                        end_idx6 =  datetime(int(malzeme_df.loc[row2, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row2, \"Baslangic_Ay\"]), 1)\n",
    "                        final_idx5 = temp_time_df[temp_time_df[\"date\"] == end_idx5].index\n",
    "                        final_idx6 = temp_time_df[temp_time_df[\"date\"] == end_idx6].index\n",
    "                        temp_time_df.loc[final_idx5, \"Fiyat\"] = fyt5\n",
    "                        temp_time_df.loc[final_idx6, \"Fiyat\"] = fyt6\n",
    "\n",
    "                    else:\n",
    "                        fyt2=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                        start_idx2 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                        end_idx2 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                        final_idx2 = temp_time_df[(temp_time_df[\"date\"] > start_idx2) & (temp_time_df[\"date\"] < end_idx2)].index\n",
    "                        temp_time_df.loc[final_idx2, \"Fiyat\"] = fyt2\n",
    "                if (row1 == len(malzeme_df)-1) or (row1 == len(malzeme_df)-2):\n",
    "                    fyt3=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                    start_idx3 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                    end_idx3 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx3 = temp_time_df[(temp_time_df[\"date\"] > start_idx3) & (temp_time_df[\"date\"] < end_idx3)].index\n",
    "                    temp_time_df.loc[final_idx3, \"Fiyat\"] = fyt3\n",
    "\n",
    "        else:\n",
    "            for row1 in malzeme_df.index:\n",
    "                fyt4=malzeme_df.loc[row1][\"     Tutar\"]\n",
    "                start_idx4 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                end_idx4 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                final_idx4 = temp_time_df[(temp_time_df[\"date\"] >= start_idx4) & (temp_time_df[\"date\"] <= end_idx4)].index\n",
    "                temp_time_df.loc[final_idx4, \"Fiyat\"] = fyt4\n",
    "\n",
    "        if (malzeme_df.loc[0, \"Baslangic_Yıl\"] >= min(horizon_saha_df_all2[\"Yıl\"].unique())) and (len(malzeme_df) > 1):\n",
    "            temp_time_df.loc[temp_time_df[~pd.isnull(temp_time_df[\"Fiyat\"])].index[0]-1, \"Fiyat\"] = malzeme_df.loc[0, \"     Tutar\"]\n",
    "        temp_time_df = temp_time_df.dropna().reset_index(drop=True)\n",
    "    except IndexError:\n",
    "        problem.append(malzeme)\n",
    "\n",
    "    h_fiyat_unique.append(temp_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_fiyat_unique = pd.concat(h_fiyat_unique)\n",
    "h_fiyat_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "h_fiyat_unique.rename(columns={\"En Güncel Kod\": \"Ürün Kodu\", \"date\": \"Date\"}, inplace=True)\n",
    "h_fiyat_unique = h_fiyat_unique.merge(eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], how=\"left\")\n",
    "h_fiyat_unique[\"En Güncel Kod\"].fillna(h_fiyat_unique[\"Ürün Kodu\"], inplace=True)\n",
    "h_fiyat_unique = h_fiyat_unique[h_fiyat_unique[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "h_fiyat_unique = h_fiyat_unique.sort_values(by=[\"En Güncel Kod\", \"Date\"]).reset_index(drop=True)\n",
    "h_fiyat_unique = h_fiyat_unique.drop(columns=\"Ürün Kodu\", axis=1)\n",
    "# Aynı aya denk gelen ürünlerin fiyatlarının ortalaması alınıp, herhangi birinde fiyat geçişi varsa 1 alınır.\n",
    "h_fiyat_unique = h_fiyat_unique.groupby([\"Date\", \"En Güncel Kod\"]).agg({\"Fiyat\": \"mean\", \"fiyat_gecisi\": \"max\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon fiyatların düzenlenmesi süresi: 0:02:30.665185\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Horizon fiyatların düzenlenmesi süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasifik Fiyatları\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik = pd.read_excel(params_[\"path\"][\"fiyat_listesi_path\"]+params_[\"files\"][\"pasifik_fiyat_file\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik.drop_duplicates(subset=fiyat_lst_pasifik.columns.to_list(), keep=\"first\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik[\"Malzeme\"] = fiyat_lst_pasifik[\"Malzeme\"].str.replace(\"-\", \"\")\n",
    "fiyat_lst_pasifik[\"Malzeme\"] = fiyat_lst_pasifik[\"Malzeme\"].astype(int)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik_df = fiyat_lst_pasifik.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik_df[\"Baslangic_Yıl\"] = fiyat_lst_pasifik_df[\"Bşl.tarihi\"].apply(lambda x: x.year)\n",
    "fiyat_lst_pasifik_df[\"Baslangic_Ay\"] = fiyat_lst_pasifik_df[\"Bşl.tarihi\"].apply(lambda x: x.month)\n",
    "fiyat_lst_pasifik_df[\"Baslangic_Gun\"] = fiyat_lst_pasifik_df[\"Bşl.tarihi\"].apply(lambda x: x.day)\n",
    "fiyat_lst_pasifik_df[\"Gecerlilik_Yıl\"] = fiyat_lst_pasifik_df[\"Gçrl.sonu\"].apply(lambda x: x.year)\n",
    "fiyat_lst_pasifik_df[\"Gecerlilik_Ay\"] = fiyat_lst_pasifik_df[\"Gçrl.sonu\"].apply(lambda x: x.month)\n",
    "fiyat_lst_pasifik_df[\"Gecerlilik_Gun\"] = fiyat_lst_pasifik_df[\"Gçrl.sonu\"].apply(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_lst_pasifik_df[\"Baslangic_Yıl\"] = fiyat_lst_pasifik_df[\"Baslangic_Yıl\"].apply(lambda x: (pasifik_df_all2[\"Date\"].max().year)+1 if x > pasifik_df_all2[\"Date\"].max().year else x)\n",
    "fiyat_lst_pasifik_df[\"Gecerlilik_Yıl\"] = fiyat_lst_pasifik_df[\"Gecerlilik_Yıl\"].apply(lambda x: (pasifik_df_all2[\"Date\"].max().year)+1 if x > pasifik_df_all2[\"Date\"].max().year else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = pasifik_df_all2[\"Date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fiyat_unique = []\n",
    "\n",
    "for malzeme in fiyat_lst_pasifik_df[\"Malzeme\"].unique():\n",
    "    temp_time_df = pd.DataFrame({\"Fiyat\": [np.nan]}, index=time_index)\n",
    "    temp_time_df = temp_time_df.reset_index().rename(columns={\"index\":\"date\"})    \n",
    "    temp_time_df[\"En Güncel Kod\"] = malzeme\n",
    "    temp_time_df[\"fiyat_gecisi\"] = 0\n",
    "    malzeme_df = fiyat_lst_pasifik_df[fiyat_lst_pasifik_df[\"Malzeme\"] == malzeme].reset_index(drop=True)\n",
    "    malzeme_df.drop(columns=[\"KşTü\", \"KşTü.1\", \"Malzeme Tanım\", \"Ana Kategori\", \"Kategori\"], axis=1, inplace=True)\n",
    "    malzeme_df.drop_duplicates(subset=malzeme_df.columns.to_list(), inplace=True, ignore_index=True)\n",
    "    malzeme_df.sort_values(by=[\"Baslangic_Yıl\", \"Baslangic_Ay\", \"Baslangic_Gun\"], ignore_index=True, inplace=True)\n",
    "    check_idx1 = []\n",
    "    if len(malzeme_df) > 1:\n",
    "        for row1 in malzeme_df.index:\n",
    "            for row2 in malzeme_df[row1+1:].index:\n",
    "                if (malzeme_df.loc[row1][\"Gecerlilik_Yıl\"] == malzeme_df.loc[row2][\"Baslangic_Yıl\"]) and (malzeme_df.loc[row1][\"Gecerlilik_Ay\"] == malzeme_df.loc[row2][\"Baslangic_Ay\"]):\n",
    "                    num_days = calendar.monthrange(int(malzeme_df.loc[row2][\"Baslangic_Yıl\"]), int(malzeme_df.loc[row2][\"Baslangic_Ay\"]))[1]\n",
    "                    fyt=((int(malzeme_df.loc[row1][\"Gecerlilik_Gun\"])*malzeme_df.loc[row1][\"Koli TL\"]) + (num_days - int(malzeme_df.loc[row2][\"Baslangic_Gun\"])+1)*malzeme_df.loc[row2][\"Koli TL\"])/num_days\n",
    "\n",
    "                    end_idx1 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx1 = temp_time_df[temp_time_df[\"date\"] == end_idx1].index\n",
    "                    temp_time_df.loc[final_idx1, \"Fiyat\"] = fyt\n",
    "                    temp_time_df.loc[final_idx1,\"fiyat_gecisi\"] = 1\n",
    "\n",
    "                elif (malzeme_df.loc[row1, \"Gecerlilik_Gun\"] == calendar.monthrange(int(malzeme_df.loc[row1][\"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1][\"Gecerlilik_Ay\"]))[1] \\\n",
    "                     and malzeme_df.loc[row2, \"Baslangic_Gun\"] == 1):\n",
    "                    fyt5=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "                    fyt6=malzeme_df.loc[row2][\"Koli TL\"]\n",
    "                    end_idx5 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    end_idx6 =  datetime(int(malzeme_df.loc[row2, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row2, \"Baslangic_Ay\"]), 1)\n",
    "                    final_idx5 = temp_time_df[temp_time_df[\"date\"] == end_idx5].index\n",
    "                    final_idx6 = temp_time_df[temp_time_df[\"date\"] == end_idx6].index\n",
    "                    temp_time_df.loc[final_idx5, \"Fiyat\"] = fyt5\n",
    "                    temp_time_df.loc[final_idx6, \"Fiyat\"] = fyt6\n",
    "\n",
    "\n",
    "                else:\n",
    "                    if malzeme_df.loc[row1, \"Baslangic_Gun\"] != 1:\n",
    "                        fyt2=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "                        start_idx2 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                        end_idx2 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                        final_idx2 = temp_time_df[(temp_time_df[\"date\"] > start_idx2) & (temp_time_df[\"date\"] < end_idx2)].index\n",
    "                        temp_time_df.loc[final_idx2, \"Fiyat\"] = fyt2\n",
    "                    else:\n",
    "                        fyt2=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "                        start_idx2 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                        end_idx2 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                        final_idx2 = temp_time_df[(temp_time_df[\"date\"] >= start_idx2) & (temp_time_df[\"date\"] < end_idx2)].index\n",
    "                        temp_time_df.loc[final_idx2, \"Fiyat\"] = fyt2\n",
    "                        \n",
    "            if (row1 == len(malzeme_df)-1) or (row1 == len(malzeme_df)-2):\n",
    "                if malzeme_df.loc[row1, \"Baslangic_Gun\"] != 1:\n",
    "                    fyt3=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "                    start_idx3 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                    end_idx3 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx3 = temp_time_df[(temp_time_df[\"date\"] > start_idx3) & (temp_time_df[\"date\"] < end_idx3)].index\n",
    "                    temp_time_df.loc[final_idx3, \"Fiyat\"] = fyt3\n",
    "                else:\n",
    "                    fyt3=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "                    start_idx3 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "                    end_idx3 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "                    final_idx3 = temp_time_df[(temp_time_df[\"date\"] >= start_idx3) & (temp_time_df[\"date\"] < end_idx3)].index\n",
    "                    temp_time_df.loc[final_idx3, \"Fiyat\"] = fyt3\n",
    "    else:\n",
    "        for row1 in malzeme_df.index:\n",
    "            fyt4=malzeme_df.loc[row1][\"Koli TL\"]\n",
    "            start_idx4 = datetime(int(malzeme_df.loc[row1, \"Baslangic_Yıl\"]), int(malzeme_df.loc[row1, \"Baslangic_Ay\"]), 1)\n",
    "            end_idx4 =  datetime(int(malzeme_df.loc[row1, \"Gecerlilik_Yıl\"]), int(malzeme_df.loc[row1, \"Gecerlilik_Ay\"]), 1)\n",
    "            final_idx4 = temp_time_df[(temp_time_df[\"date\"] >= start_idx4) & (temp_time_df[\"date\"] <= end_idx4)].index\n",
    "            temp_time_df.loc[final_idx4, \"Fiyat\"] = fyt4\n",
    "    \n",
    "    if (malzeme_df.loc[0, \"Baslangic_Yıl\"] >= min(pasifik_df_all2[\"Yıl\"].unique())) and (len(malzeme_df) > 1):\n",
    "        temp_time_df.loc[temp_time_df[~pd.isnull(temp_time_df[\"Fiyat\"])].index[0]-1, \"Fiyat\"] = malzeme_df.loc[0, \"Koli TL\"]\n",
    "    temp_time_df = temp_time_df.dropna().reset_index(drop=True)\n",
    "        \n",
    "    p_fiyat_unique.append(temp_time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fiyat_unique = pd.concat(p_fiyat_unique)\n",
    "p_fiyat_unique.reset_index(drop=True, inplace=True)\n",
    "\n",
    "p_fiyat_unique.rename(columns={\"En Güncel Kod\": \"Ürün Kodu\", \"date\": \"Date\"}, inplace=True)\n",
    "p_fiyat_unique = p_fiyat_unique.merge(eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], how=\"left\")\n",
    "p_fiyat_unique[\"En Güncel Kod\"].fillna(p_fiyat_unique[\"Ürün Kodu\"], inplace=True)\n",
    "p_fiyat_unique = p_fiyat_unique[p_fiyat_unique[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "p_fiyat_unique = p_fiyat_unique.sort_values(by=[\"En Güncel Kod\", \"Date\"]).reset_index(drop=True)\n",
    "p_fiyat_unique = p_fiyat_unique.drop(columns=\"Ürün Kodu\", axis=1)\n",
    "# Aynı aya denk gelen ürünlerin fiyatlarının ortalaması alınıp, herhangi birinde fiyat geçişi varsa 1 alınır.\n",
    "p_fiyat_unique = p_fiyat_unique.groupby([\"Date\", \"En Güncel Kod\"]).agg({\"Fiyat\": \"mean\", \"fiyat_gecisi\": \"max\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasifik fiyatların düzenlenmesi süresi: 0:02:19.669212\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Pasifik fiyatların düzenlenmesi süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Portföy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasifik Portföy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_portfoy_df2 = pd.merge(pasifik_portfoy_df, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], how=\"left\", left_on=\"Kod\", right_on=\"Ürün Kodu\")\n",
    "pasifik_portfoy_df2[\"En Güncel Kod\"] = pasifik_portfoy_df2[\"En Güncel Kod\"].fillna(pasifik_portfoy_df2[\"Kod\"])\n",
    "pasifik_portfoy_df2.drop(\"Ürün Kodu\", axis=1, inplace=True)\n",
    "pasifik_portfoy_df2 = pasifik_portfoy_df2[pasifik_portfoy_df2[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "pasifik_portfoy_df2[\"Portfoy\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizon Portföy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_portfoy_df2 = pd.merge(horizon_portfoy_df, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], how=\"left\", left_on=\"Kod\", right_on=\"Ürün Kodu\")\n",
    "horizon_portfoy_df2[\"En Güncel Kod\"] = horizon_portfoy_df2[\"En Güncel Kod\"].fillna(horizon_portfoy_df2[\"Kod\"])\n",
    "horizon_portfoy_df2.drop(\"Ürün Kodu\", axis=1, inplace=True)\n",
    "horizon_portfoy_df2 = horizon_portfoy_df2[horizon_portfoy_df2[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "horizon_portfoy_df2[\"Portfoy\"] = 1\n",
    "horizon_portfoy_df2 = horizon_portfoy_df2[~((horizon_portfoy_df2[\"Kod\"] == 135901))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BTT Portföy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_portfoy_df2 = pd.merge(btt_portfoy_df, eslenik_kod_df[[\"Ürün Kodu\", \"En Güncel Kod\"]], how=\"left\", left_on=\"Kod\", right_on=\"Ürün Kodu\")\n",
    "btt_portfoy_df2[\"En Güncel Kod\"] = btt_portfoy_df2[\"En Güncel Kod\"].fillna(btt_portfoy_df2[\"Kod\"])\n",
    "btt_portfoy_df2.drop(\"Ürün Kodu\", axis=1, inplace=True)\n",
    "btt_portfoy_df2 = btt_portfoy_df2[btt_portfoy_df2[\"En Güncel Kod\"] != \"delist\"].reset_index(drop=True)\n",
    "btt_portfoy_df2[\"Portfoy\"] = 1\n",
    "btt_portfoy_df2 = btt_portfoy_df2[~((btt_portfoy_df2[\"Kod\"] == 135901))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portföy Kapsamındaki Sales Dataları"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3 = pd.merge(pasifik_df_all2,pasifik_portfoy_df2[[\"En Güncel Kod\", \"Portfoy\"]], on=\"En Güncel Kod\", how=\"left\")\n",
    "btt_df_all3 = pd.merge(btt_df_all2,btt_portfoy_df2[[\"En Güncel Kod\", \"Portfoy\"]], on=\"En Güncel Kod\", how=\"left\")\n",
    "horizon_saha_df_all3 = pd.merge(horizon_saha_df_all2, horizon_portfoy_df2[[\"En Güncel Kod\", \"Portfoy\"]], on=\"En Güncel Kod\", how=\"left\")\n",
    "pasifik_df_all3[\"Portfoy\"].fillna(0, inplace=True)\n",
    "btt_df_all3[\"Portfoy\"].fillna(0, inplace=True)\n",
    "horizon_saha_df_all3[\"Portfoy\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65271, 11), (17549, 11), (331517, 10))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasifik_df_all3.shape, btt_df_all3.shape, horizon_saha_df_all3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3.drop_duplicates(ignore_index=True, inplace=True)\n",
    "btt_df_all3.drop_duplicates(ignore_index=True, inplace=True)\n",
    "horizon_saha_df_all3.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Datalara Calender Eklenmesi\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jan 2016\n",
       "1     Feb 2016\n",
       "2     Mar 2016\n",
       "3     Apr 2016\n",
       "4     May 2016\n",
       "5     Jun 2016\n",
       "6     Jul 2016\n",
       "7     Aug 2016\n",
       "8     Sep 2016\n",
       "9     Oct 2016\n",
       "10    Nov 2016\n",
       "11    Dec 2016\n",
       "12    Jan 2017\n",
       "13    Feb 2017\n",
       "14    Mar 2017\n",
       "15    Apr 2017\n",
       "16    May 2017\n",
       "17    Jun 2017\n",
       "18    Jul 2017\n",
       "19    Aug 2017\n",
       "20    Sep 2017\n",
       "21    Oct 2017\n",
       "22    Nov 2017\n",
       "23    Dec 2017\n",
       "24    Jan 2018\n",
       "25    Feb 2018\n",
       "26    Mar 2018\n",
       "27    Apr 2018\n",
       "28    May 2018\n",
       "29    Jun 2018\n",
       "30    Jul 2018\n",
       "31    Aug 2018\n",
       "32    Sep 2018\n",
       "33    Oct 2018\n",
       "34    Nov 2018\n",
       "35    Dec 2018\n",
       "36    Jan 2019\n",
       "37    Feb 2019\n",
       "38    Mar 2019\n",
       "39    Apr 2019\n",
       "40    May 2019\n",
       "41    Jun 2019\n",
       "42    Jul 2019\n",
       "43    Aug 2019\n",
       "44    Sep 2019\n",
       "45    Oct 2019\n",
       "46    Nov 2019\n",
       "47    Dec 2019\n",
       "48    Jan 2020\n",
       "49    Feb 2020\n",
       "50    Mar 2020\n",
       "51    Apr 2020\n",
       "52    May 2020\n",
       "53    Jun 2020\n",
       "54    Jul 2020\n",
       "55    Aug 2020\n",
       "56    Sep 2020\n",
       "57    Oct 2020\n",
       "58    Nov 2020\n",
       "59    Dec 2020\n",
       "60    Jan 2021\n",
       "61    Feb 2021\n",
       "62    Mar 2021\n",
       "63    Apr 2021\n",
       "64    May 2021\n",
       "65    Jun 2021\n",
       "66    Jul 2021\n",
       "67    Aug 2021\n",
       "68    Sep 2021\n",
       "69    Oct 2021\n",
       "70    Nov 2021\n",
       "71    Dec 2021\n",
       "72    Jan 2022\n",
       "73    Feb 2022\n",
       "74    Mar 2022\n",
       "75    Apr 2022\n",
       "76    May 2022\n",
       "77    Jun 2022\n",
       "78    Jul 2022\n",
       "79    Aug 2022\n",
       "80    Sep 2022\n",
       "81    Oct 2022\n",
       "82    Nov 2022\n",
       "83    Dec 2022\n",
       "84    Jan 2023\n",
       "85    Feb 2023\n",
       "86    Mar 2023\n",
       "87    Apr 2023\n",
       "88    May 2023\n",
       "89    Jun 2023\n",
       "90    Jul 2023\n",
       "91    Aug 2023\n",
       "92    Sep 2023\n",
       "93    Oct 2023\n",
       "94    Nov 2023\n",
       "95    Dec 2023\n",
       "Name: DATE, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calender_df.pop(\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3 = pd.merge(pasifik_df_all3, calender_df, on=[\"Yıl\", \"Ay\"], how=\"left\")\n",
    "btt_df_all3 = pd.merge(btt_df_all3, calender_df, on=[\"Yıl\", \"Ay\"], how=\"left\")\n",
    "horizon_saha_df_all3 = pd.merge(horizon_saha_df_all3, calender_df, on=[\"Yıl\", \"Ay\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataların Fiyat Ve Aktiviteler İle Birleştirilmesi\n",
    "---\n",
    "\n",
    "# Not:\n",
    "---\n",
    "### 1) BTT aktivite verisi için Horizon kısmındaki \"Geleneksel Kanal\" kullanılması istendi.\n",
    "### 2) BTT fiyat geçişleri için Horizon fiyat geçişleri baz alındı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62095, 28), (331147, 27), (17549, 28))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasifik_df_all3.shape, horizon_saha_df_all3.shape, btt_df_all3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3 = pasifik_df_all3.merge(p_fiyat_unique, how=\"left\", on=[\"Date\", \"En Güncel Kod\"])\n",
    "pasifik_aktivite_df3.rename(columns={\"Müşteri Grup\": \"Grup Adı\", \"Grup adı\": \"Grup Adı\"}, inplace=True)\n",
    "pasifik_df_all3 = pd.merge(pasifik_df_all3, pasifik_aktivite_df3[[\"Yıl\", \"Ay\", \"Grup Adı\", \"En Güncel Kod\", \n",
    "                                                                  \"Raf Tavsiye Satış Fiyatı\", \"İndirimli Raf Satış Fiyatı\", \"İndirim %\",\n",
    "                                                                  \"Aktivite Tipi\"]], \n",
    "                           left_on=[\"Yıl\", \"Ay\", \"Grup Adı\", \"En Güncel Kod\"], \n",
    "                           right_on=[\"Yıl\", \"Ay\", \"Grup Adı\", \"En Güncel Kod\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "saha_aktivite_detay3.rename(columns={\"Grup adı\": \"Grup Adı\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_all3 = horizon_saha_df_all3.merge(h_fiyat_unique, how=\"left\", on=[\"Date\", \"En Güncel Kod\"])\n",
    "horizon_saha_df_all3 = horizon_saha_df_all3.merge(saha_aktivite_detay3[['Ciro (Kull. İade Düş.)', 'Promosyon Tutarı', \n",
    "                                                                        'İskonto %', 'En Güncel Kod', \"Yıl\", \"Ay\", \"Grup Adı\"]],\n",
    "                                                  on=[\"En Güncel Kod\", \"Yıl\", \"Ay\", \"Grup Adı\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_all3.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_df_all3 = btt_df_all3.merge(h_fiyat_unique, how=\"left\", on=[\"Date\", \"En Güncel Kod\"])\n",
    "btt_aktivite = saha_aktivite_detay3[saha_aktivite_detay3[\"Grup Adı\"] == \"GELENEKSEL KANAL\"].reset_index(drop=True)\n",
    "\n",
    "btt_df_all3 = btt_df_all3.merge(btt_aktivite[['Ciro (Kull. İade Düş.)', 'Promosyon Tutarı', \n",
    "                                              'İskonto %', 'En Güncel Kod', \"Yıl\", \"Ay\"]],\n",
    "                                on=[\"En Güncel Kod\", \"Yıl\", \"Ay\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_df_all3.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sütun İsimlerini İngilizce Karaktere Çevirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_col_name(dff_):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    dff_: dataframe\n",
    "    Sütun ismini değiştirmek istediğiniz dataframe'i yazınız.\n",
    "    \n",
    "    Returns: Liste\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    chng_letters = list(zip([\"ç\", \"ğ\", \"ı\", \"ö\", \"ş\", \"ü\", \" \", \"%\", \".\", \"(\", \")\", \"-\"], \n",
    "                            [\"c\", \"g\", \"i\", \"o\", \"s\", \"u\", \"_\", \"\", \"\", \"\", \"\", \"_\"]))\n",
    "    new_cols = []\n",
    "    for col in dff_.columns.str.lower():\n",
    "        for letter in range(len(chng_letters)):\n",
    "            col = col.replace(chng_letters[letter][0], chng_letters[letter][1])\n",
    "            if letter == len(chng_letters) - 1:\n",
    "                new_cols.append(col)\n",
    "            else:\n",
    "                pass\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3.columns = change_col_name(pasifik_df_all3)\n",
    "horizon_saha_df_all3.columns = change_col_name(horizon_saha_df_all3)\n",
    "btt_df_all3.columns = change_col_name(btt_df_all3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pasifikte Aktivite Tipi Verisi Eksik Olan Verilere \"Yok\" yazıldı\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_all3[\"aktivite_tipi\"].fillna(\"Yok\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted = pasifik_df_all3.copy()\n",
    "horizon_saha_df_sorted = horizon_saha_df_all3.copy()\n",
    "btt_df_sorted = btt_df_all3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik = pasifik_df_sorted.copy()\n",
    "df_btt = btt_df_sorted.copy()\n",
    "df_horizon = horizon_saha_df_sorted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Sütun isim uzunluğunun 32'yi geçmemesi için\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik.columns = [i[:32] if len(i) > 32 else i for i in df_pasifik.columns]\n",
    "df_horizon.columns = [i[:32] if len(i) > 32 else i for i in df_horizon.columns]\n",
    "df_btt.columns = [i[:32] if len(i) > 32 else i for i in df_btt.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fiyat_unique.rename(columns={\"Date\": \"date\", \"En Güncel Kod\": \"en_guncel_kod\", \"Fiyat\": \"fiyat\"}, inplace=True)\n",
    "h_fiyat_unique.rename(columns={\"Date\": \"date\", \"En Güncel Kod\": \"en_guncel_kod\", \"Fiyat\": \"fiyat\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fiyat_unique[\"kanal\"] = \"pasifik\"\n",
    "h_fiyat_unique[\"kanal\"] = \"horizon\"\n",
    "fiyat_unique = pd.concat([p_fiyat_unique, h_fiyat_unique], axis=0, ignore_index=True)\n",
    "#fiyat_unique.to_csv(\"../data/fiyat_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik3 = df_pasifik.copy()\n",
    "df_btt3 = df_btt.copy()\n",
    "df_horizon3 = df_horizon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik4 = df_pasifik3.drop(columns=['fiyat', 'fiyat_gecisi'], axis=1)\n",
    "df_pasifik4 = df_pasifik4.merge(p_fiyat_unique, how=\"left\", on=[\"date\", \"en_guncel_kod\"])\n",
    "\n",
    "df_horizon4 = df_horizon3.drop(columns=['fiyat', 'fiyat_gecisi'], axis=1)\n",
    "df_horizon4 = df_horizon4.merge(h_fiyat_unique, how=\"left\", on=[\"date\", \"en_guncel_kod\"])\n",
    "\n",
    "df_btt4 = df_btt3.drop(columns=['fiyat', 'fiyat_gecisi'], axis=1)\n",
    "df_btt4 = df_btt4.merge(h_fiyat_unique, how=\"left\", on=[\"date\", \"en_guncel_kod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_aktivite_df3.columns = change_col_name(pasifik_aktivite_df3)\n",
    "saha_aktivite_detay3.columns = change_col_name(saha_aktivite_detay3)\n",
    "pasifik_aktivite_df3.rename(columns={\"i̇ndirim_\": \"indirim_\"}, inplace=True)\n",
    "saha_aktivite_detay3.rename(columns={\"i̇i̇skonto_\": \"iskonto_\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik4 = df_pasifik4.drop(columns=['raf_tavsiye_satis_fiyati', 'i̇ndirimli_raf_satis_fiyati', \n",
    "                                        'i̇ndirim_', 'aktivite_tipi'], axis=1)\n",
    "\n",
    "df_horizon4 = df_horizon4.drop(columns=['ciro_kull_i̇ade_dus', 'promosyon_tutari', 'i̇skonto_'], axis=1)\n",
    "df_btt4 = df_btt4.drop(columns=['ciro_kull_i̇ade_dus', 'promosyon_tutari', 'i̇skonto_'], axis=1)\n",
    "\n",
    "pasifik_aktivite_df3.rename(columns={\"Müşteri Grup\": \"Grup adı\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pasifik5 = pd.merge(df_pasifik4, pasifik_aktivite_df3[['yil', 'ay', 'grup_adi', 'en_guncel_kod', \n",
    "                                                          'raf_tavsiye_satis_fiyati', 'i̇ndirimli_raf_satis_fiyati', 'indirim_', \n",
    "                                                          'aktivite_tipi']], \n",
    "                           left_on=['yil', 'ay', 'grup_adi', 'en_guncel_kod'], \n",
    "                           right_on=['yil', 'ay', 'grup_adi', 'en_guncel_kod'], how=\"left\")\n",
    "\n",
    "df_horizon5 = df_horizon4.merge(saha_aktivite_detay3[['yil', 'ay', 'grup_adi', 'ciro_kull_i̇ade_dus', \n",
    "                                                      'promosyon_tutari', 'i̇skonto_', 'en_guncel_kod']],\n",
    "                                on=['en_guncel_kod', 'yil', 'ay', 'grup_adi'], how=\"left\")\n",
    "\n",
    "btt_aktivite = saha_aktivite_detay3[saha_aktivite_detay3[\"grup_adi\"] == \"GELENEKSEL KANAL\"].reset_index(drop=True)\n",
    "btt_aktivite[\"grup_adi\"] = \"BTT\"\n",
    "\n",
    "df_btt5 = df_btt4.merge(btt_aktivite[['yil', 'ay', 'grup_adi', 'ciro_kull_i̇ade_dus', \n",
    "                                      'promosyon_tutari', 'i̇skonto_', 'en_guncel_kod']],\n",
    "                        on=['en_guncel_kod', 'yil', 'ay', 'grup_adi'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horizon5.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btt5.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted = df_pasifik5.copy()\n",
    "horizon_saha_df_sorted = df_horizon5.copy()\n",
    "btt_df_sorted = df_btt5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_backup = pasifik_df_sorted.copy()\n",
    "hor_backup = horizon_saha_df_sorted.copy()\n",
    "btt_backup = btt_df_sorted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Kapsamı yeniden düzenleme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted[\"indirim__\"] = [0 if akt < 0 else akt for akt in pasifik_df_sorted[\"indirim_\"]]\n",
    "pasifik_df_sorted.drop(\"indirim_\", axis=1, inplace=True)\n",
    "\n",
    "horizon_saha_df_sorted[\"i̇skonto__\"] = [0 if ((akt >= 0.35) or (akt <=0.01)) else akt for akt in horizon_saha_df_sorted[\"i̇skonto_\"]]\n",
    "horizon_saha_df_sorted.drop(\"i̇skonto_\", axis=1, inplace=True)\n",
    "\n",
    "btt_df_sorted[\"i̇skonto__\"] = [0 if ((akt >= 0.35) or (akt <=0.01)) else akt for akt in btt_df_sorted[\"i̇skonto_\"]]\n",
    "btt_df_sorted.drop(\"i̇skonto_\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "chng_cols = dict(zip(['Yıl', 'Ay', 'No_of_days', 'Weekdays_n', 'Weekdays_Ratio', 'Weekend_n',\n",
    "                      'Weekend_Ratio', 'Actual_Holiday_n', 'Actual_Holiday_Ratio',\n",
    "                      'Total_Holiday_n', 'Total_Holiday_Ratio', 'School_Day_n',\n",
    "                      'School_Day_Ratio', 'School_Day_brdg_n', 'School_Day_brdg_Ratio',\n",
    "                      'Ramadan_n', 'Ramadan_Ratio', 'Pandemic', 'Lockdown'],\n",
    "                     \n",
    "                     [\"yil\", \"ay\", \"no_of_days\", \"weekdays_n\", \"weekdays_ratio\", \"weekend_n\", \n",
    "                      \"weekend_ratio\", \"actual_holiday_n\", \"actual_holiday_ratio\",\n",
    "                      \"total_holiday_n\", \"total_holiday_ratio\", \"school_day_n\", \n",
    "                      \"school_day_ratio\", \"school_day_brdg_n\", \"school_day_brdg_ratio\",\n",
    "                      \"ramadan_n\", \"ramadan_ratio\", \"pandemic\", \"lockdown\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "calender_df.rename(columns=chng_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted[\"indirim__\"].fillna(0, inplace=True)\n",
    "horizon_saha_df_sorted[\"i̇skonto__\"].fillna(0, inplace=True)\n",
    "btt_df_sorted[\"i̇skonto__\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_sorted.rename(columns={\"i̇skonto__\": \"indirim__\"}, inplace=True)\n",
    "btt_df_sorted.rename(columns={\"i̇skonto__\": \"indirim__\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_backup = pasifik_df_sorted.copy()\n",
    "hor_backup = horizon_saha_df_sorted.copy()\n",
    "btt_backup = btt_df_sorted.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Bir önceki aya yansımış aktiviteleri düzenleme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aktivite_regulation(df):\n",
    "    df_all = []\n",
    "    for sku in df[\"en_guncel_kod\"].unique():\n",
    "        for grup in df[\"grup_adi\"].unique():\n",
    "            test = df[(df[\"en_guncel_kod\"] == sku) & (df[\"grup_adi\"] == grup)]\n",
    "            for idx in test.index:\n",
    "                if (idx-2 not in test.index) and (idx-1 in test.index): # bir öncekine bakacak. ilk ve sonraki satıra bakacak. -1 götür\n",
    "                    if test.loc[idx-1, \"koli\"] > test.loc[idx, \"koli\"]:\n",
    "                        test.loc[idx-1, \"indirim__\"] += test.loc[idx, \"indirim__\"]\n",
    "                        test.loc[idx, \"indirim__\"] = 0\n",
    "                elif (idx-1 not in test.index): # ilk satırdayız. pass\n",
    "                    pass\n",
    "                else:\n",
    "                    dic = {}\n",
    "                    dic.update({idx-2: test.loc[idx-2, \"koli\"], \n",
    "                                idx-1: test.loc[idx-1, \"koli\"],\n",
    "                                idx: test.loc[idx, \"koli\"]})\n",
    "                    max_idx = max(dic, key=dic.get)\n",
    "                    if max_idx == idx:\n",
    "                        pass\n",
    "                    else:\n",
    "                        test.loc[max_idx, \"indirim__\"] += test.loc[idx, \"indirim__\"]\n",
    "                        test.loc[idx, \"indirim__\"] = 0\n",
    "            df_all.append(test)\n",
    "    df_all = pd.concat(df_all)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_sorted, btt_df_sorted = aktivite_regulation(horizon_saha_df_sorted), aktivite_regulation(btt_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktivite Regulation süresi: 0:12:41.945158\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Aktivite Regulation süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasifik_aktivite_regulation(df):\n",
    "    df_all = []\n",
    "    for sku in df[\"en_guncel_kod\"].unique():\n",
    "        for grup in df[\"grup_adi\"].unique():\n",
    "            test = df[(df[\"en_guncel_kod\"] == sku) & (df[\"grup_adi\"] == grup)]\n",
    "            aktivite_tip_index = test[~test.aktivite_tipi.isna()].index.to_list()\n",
    "            for idx in aktivite_tip_index:\n",
    "                if idx == test.index[0]: # ilk satırsa atla\n",
    "                    pass\n",
    "                elif idx-1 in aktivite_tip_index: #bir önceki satırda aktivite varsa atla\n",
    "                    pass\n",
    "                else:\n",
    "                    if test.loc[idx, 'koli'] < test.loc[idx-1, 'koli']: # adet sayısı bir önceki satırdan küçükse \n",
    "                        test.loc[idx-1, 'aktivite_tipi'] = test.loc[idx, 'aktivite_tipi'] # aktiviteyi bir önceki satıra yaz\n",
    "                        test.loc[idx, 'aktivite_tipi'] = np.nan\n",
    "                        aktivite_tip_index.remove(idx) #listeden remove et ki bir alt satırda varsa önceki var mı kontrolüne takılmasın\n",
    "                        aktivite_tip_index.insert(0,0) #döngü listedeki elementlerin index'ine göre devam ettiği için en başa 0 insert et\n",
    "\n",
    "            indirim_index = test[test.indirim__ != 0].index.to_list()\n",
    "            for idx in indirim_index:\n",
    "                if idx == test.index[0]: # ilk satır\n",
    "                    pass \n",
    "                elif idx-1 in indirim_index: #bir önceki satırda indirim yüzdesi varsa atla\n",
    "                    pass \n",
    "                else:\n",
    "                    if test.loc[idx, 'koli'] < test.loc[idx-1, 'koli']:\n",
    "                        test.loc[idx-1, 'indirim__'] = test.loc[idx, 'indirim__'] #bir üste taşındı\n",
    "                        test.loc[idx, 'indirim__'] = 0  \n",
    "                        indirim_index.remove(idx)  #listeden remove et ki bir alt satırda varsa önceki var mı kontrolüne takılmasın\n",
    "                        indirim_index.insert(0, 0) #döngü listedeki elementlerin index'ine göre devam ettiği için en başa 0 insert et\n",
    "            df_all.append(test)\n",
    "    df_all = pd.concat(df_all)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted = pasifik_aktivite_regulation(pasifik_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasifik Aktivite Regulation süresi: 0:00:44.414135\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Pasifik Aktivite Regulation süresi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted.sort_values(by=[\"en_guncel_kod\", \"grup_adi\", \"date\"], ignore_index=True, inplace=True)\n",
    "horizon_saha_df_sorted.sort_values(by=[\"en_guncel_kod\", \"grup_adi\", \"date\"], ignore_index=True, inplace=True)\n",
    "btt_df_sorted.sort_values(by=[\"en_guncel_kod\", \"grup_adi\", \"date\"], ignore_index=True, inplace=True)\n",
    "\n",
    "btt_df_sorted.drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\", \"date\"], keep=\"first\", ignore_index=True, inplace=True)\n",
    "horizon_saha_df_sorted.drop_duplicates(subset=[\"date\", \"grup_adi\", \"en_guncel_kod\"], keep=\"first\", ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_sorted[\"aktivite_tipi\"] = np.nan\n",
    "btt_df_sorted[\"aktivite_tipi\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted.rename(columns={'i̇ndirimli_raf_satis_fiyati': 'ciro_kull_i̇ade_dus',\n",
    "                                  'raf_tavsiye_satis_fiyati': 'promosyon_tutari'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted[\"Kanal\"] = \"pasifik\"\n",
    "horizon_saha_df_sorted[\"Kanal\"] = \"horizon\"\n",
    "btt_df_sorted[\"Kanal\"] = \"btt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_df_eski = [] \n",
    "for docs_ in btt_lst:\n",
    "    horizon_df_eski.append(pd.read_excel(params_[\"path\"][\"horizon_koli_path\"]+docs_, skiprows=1, sheet_name=\"Horizon Saha Satış\", usecols=\"B:N\").rename(columns=chng_cols_beginning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_df_eski = pd.concat(horizon_df_eski, ignore_index=True)\n",
    "hor_kat_marka = horizon_df_eski.drop_duplicates(subset=[\"Kategori Adı\", \"Marka Adı\", \"Ürün Kodu\"], ignore_index=True)[[\"Kategori Adı\", \"Marka Adı\", \"Ürün Kodu\"]]\n",
    "hor_kat_marka.rename(columns={\"Kategori Adı\": \"kategori_adi\", \"Marka Adı\": \"marka_adi\", \"Ürün Kodu\": \"en_guncel_kod\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_sorted = horizon_saha_df_sorted.merge(hor_kat_marka, on=\"en_guncel_kod\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pasifik Marka İsmi Düzenleme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_marka = pasifik_df_all[[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"]].drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"], ignore_index=True)\n",
    "pasifik_marka.rename(columns={\"Grup Adı\": \"grup_adi\", \"En Güncel Kod\": \"en_guncel_kod\", \"Marka Adı\": \"marka_adi\"}, inplace=True)\n",
    "pasifik_marka.grup_adi = pasifik_marka.grup_adi.apply(lambda x: \"Diğer_Pasifik\" if x==\"Diğer\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted = pasifik_df_sorted.merge(pasifik_marka, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Horizon Marka İsmi Düzenleme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_marka = horizon_saha_df_all[[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"]].drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"], ignore_index=True)\n",
    "horizon_marka.rename(columns={\"Grup Adı\": \"grup_adi\", \"En Güncel Kod\": \"en_guncel_kod\", \"Marka Adı\": \"marka_adi\"}, inplace=True)\n",
    "horizon_marka.grup_adi = horizon_marka.grup_adi.apply(lambda x: \"Diğer_Horizon\" if x==\"Diğer\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_marka[\"marka_adi\"] = horizon_marka[\"marka_adi\"].apply(lambda x: \"ALTINBAŞAK\" if x == \"ÜLKER GRİSSİNİ\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    horizon_saha_df_sorted.drop(columns=[\"marka_adi\"], axis=1, inplace=True)\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_saha_df_sorted = horizon_saha_df_sorted.merge(horizon_marka, how=\"left\")\n",
    "horizon_saha_df_sorted.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# BTT Marka İsmi Düzenleme\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_marka = btt_df_all[[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"]].drop_duplicates(subset=[\"Grup Adı\", \"En Güncel Kod\", \"Marka Adı\"], ignore_index=True)\n",
    "btt_marka.rename(columns={\"Grup Adı\": \"grup_adi\", \"En Güncel Kod\": \"en_guncel_kod\", \"Marka Adı\": \"marka_adi\"}, inplace=True)\n",
    "btt_marka.grup_adi = btt_marka.grup_adi.apply(lambda x: \"Diğer_Horizon\" if x==\"Diğer\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_marka[\"marka_adi\"] = btt_marka[\"marka_adi\"].apply(lambda x: \"ALTINBAŞAK\" if x == \"ÜLKER GRİSSİNİ\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['marka_adi'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    btt_df_sorted.drop(columns=[\"marka_adi\"], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "btt_df_sorted = btt_df_sorted.merge(btt_marka, how=\"left\")\n",
    "btt_df_sorted.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([pasifik_df_sorted, horizon_saha_df_sorted, btt_df_sorted], axis=0, ignore_index=True)\n",
    "df_all.drop(columns=\"kanal\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[[\"yil\", \"ay\", \"Kanal\"]+df_all.drop(columns=[\"yil\", \"ay\", \"Kanal\"]).columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.aktivite_tipi.fillna(\"Yok\", inplace=True)\n",
    "try: df_all.drop(columns=[\"durum\", \"promosyon_tutari\", \"ciro_kull_i̇ade_dus\"], axis=1, inplace=True)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"koli_new\"] = df_all[\"koli\"]\n",
    "df_all[\"koli_new\"] = np.where(df_all[\"koli_new\"] == 0, np.nan, df_all[\"koli_new\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[df_all[\"portfoy\"] == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Geçmiş ayları çalıştırmak için bu kısmı kullanıyoruz\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[~(df_all[\"en_guncel_kod\"].isin([\"Delist\", \" Delist\", \" Delist \", \"Delist \", \"delist\", \" delist\", \" delist \", \"delist \"]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_kat_unique = df_all.drop_duplicates(subset=[\"Kanal\", \"kategori_adi\"], ignore_index=True)[[\"Kanal\", \"kategori_adi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"back_to_school\"] = df_all[\"ay\"].apply(lambda x: 1 if x in [9, 2] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_kat_ = []\n",
    "corr_ = []\n",
    "dt_feature_importance_ = []\n",
    "xgb_feature_importance_ = []\n",
    "rf_feature_importance_ = []\n",
    "\n",
    "for idx in kanal_kat_unique.index:\n",
    "    tmp = df_all[(df_all[\"Kanal\"] == kanal_kat_unique[\"Kanal\"][idx]) & (df_all[\"kategori_adi\"] == kanal_kat_unique[\"kategori_adi\"][idx])]\n",
    "    tmp.fiyat.fillna(0, inplace=True)\n",
    "    tmp_corr = tmp[[\"koli\", \"no_of_days\", 'back_to_school', 'weekdays_ratio', 'weekend_ratio',\n",
    "                    'total_holiday_ratio', 'school_day_ratio', 'ramadan_ratio', 'indirim__', 'fiyat']].corr()\n",
    "    tmp_dt = tmp[[\"koli\", \"no_of_days\", 'back_to_school', 'weekdays_ratio', 'weekend_ratio',\n",
    "                  'total_holiday_ratio', 'school_day_ratio', 'ramadan_ratio', 'indirim__', 'fiyat']]\n",
    "    X = tmp_dt.drop(\"koli\", axis=1)\n",
    "    y = tmp_dt.koli\n",
    "    dt = DecisionTreeRegressor().fit(X, y)\n",
    "    xgb = XGBRegressor().fit(X, y)\n",
    "    rf = RandomForestRegressor().fit(X, y)\n",
    "    \n",
    "    dt_importance = dt.feature_importances_\n",
    "    xgb_importance = xgb.feature_importances_\n",
    "    rf_importance = rf.feature_importances_\n",
    "    dt_feat_imprtnce = {}\n",
    "    xgb_feat_imprtnce = {}\n",
    "    rf_feat_imprtnce = {}\n",
    "    for i, v in enumerate(dt_importance):\n",
    "        dt_feat_imprtnce.update({X.columns[i]: v})\n",
    "    for i, v in enumerate(xgb_importance):\n",
    "        xgb_feat_imprtnce.update({X.columns[i]: v})\n",
    "    for i, v in enumerate(rf_importance):\n",
    "        rf_feat_imprtnce.update({X.columns[i]: v})\n",
    "    dt_feat_imprtnce = {k: v for k, v in sorted(dt_feat_imprtnce.items(), key=lambda item: item[1], reverse=True)}\n",
    "    xgb_feat_imprtnce = {k: v for k, v in sorted(xgb_feat_imprtnce.items(), key=lambda item: item[1], reverse=True)}\n",
    "    rf_feat_imprtnce = {k: v for k, v in sorted(rf_feat_imprtnce.items(), key=lambda item: item[1], reverse=True)}\n",
    "    kanal_kat_.append(kanal_kat_unique.loc[idx, \"Kanal\"] + \"_\" + kanal_kat_unique.loc[idx, \"kategori_adi\"])\n",
    "    corr_.append(tmp_corr)\n",
    "    dt_feature_importance_.append(dt_feat_imprtnce)\n",
    "    xgb_feature_importance_.append(xgb_feat_imprtnce)\n",
    "    rf_feature_importance_.append(rf_feat_imprtnce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ = pd.DataFrame({\"hierarchy\": kanal_kat_,\n",
    "                         \"correlation\": corr_,\n",
    "                         \"dt_fi\": dt_feature_importance_,\n",
    "                         \"xgb_fi\": xgb_feature_importance_,\n",
    "                         \"rf_fi\": rf_feature_importance_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_backup = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Unique Fiyatların düzenlenmesi. Bazı kısımlarda na geldi çünkü önceki tarihlerin fiyatları yok. Data 2017 Ocak'ta başlıyor ama fiyat datası 2017 Aralıkta başlıyor. Bu durumdan dolayı missing imputation yaptım.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_unique.rename(columns={\"kanal\": \"Kanal\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v2 = df_all.copy()\n",
    "df_all_v2.en_guncel_kod = df_all_v2.en_guncel_kod.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_unique = fiyat_unique[~(fiyat_unique[\"en_guncel_kod\"].isin([\"Delist\", \" Delist\", \" Delist \", \"Delist \", \"delist\", \" delist\", \" delist \", \"delist \"]))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_unique.en_guncel_kod = fiyat_unique.en_guncel_kod.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_all_v2.drop(columns=[\"fiyat\", \"fiyat_gecisi\"], axis=1, inplace=True)\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v2 = df_all_v2.merge(fiyat_unique, how=\"left\", on=[\"date\", \"en_guncel_kod\", \"Kanal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_fiyat_ = df_all_v2[df_all_v2[\"fiyat\"].isna()][[\"grup_adi\", \"en_guncel_kod\"]].drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v3 = df_all_v2.copy()\n",
    "df_all_v3.fiyat.fillna(method=\"bfill\", inplace=True)\n",
    "df_all_v3.fiyat.fillna(0, inplace=True)\n",
    "df_all_v3.fiyat_gecisi.fillna(method=\"bfill\", inplace=True)\n",
    "df_all_v3.fiyat_gecisi.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Koli Missing Imputation (Mean)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_imputation(df__, unique_grup, unique_sku, loop):\n",
    "    print(\"Başla ------>\", unique_grup[loop], unique_sku[loop])\n",
    "    tmp = df__[(df__[\"grup_adi\"] == unique_grup[loop]) & (df__[\"en_guncel_kod\"] == unique_sku[loop])]\n",
    "    if tmp[\"koli_new\"].isna().sum() > 0:\n",
    "        mean = tmp[\"koli_new\"].mean()\n",
    "        tmp.koli_new.fillna(mean, inplace=True)\n",
    "    else: pass\n",
    "    print(\"Bitti ------>\", unique_grup[loop], unique_sku[loop])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = df_all_v3[[\"grup_adi\", \"en_guncel_kod\"]].drop_duplicates(ignore_index=True)\n",
    "unique_grup = unique_list[\"grup_adi\"].to_list()\n",
    "unique_sku = unique_list[\"en_guncel_kod\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v4 = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    df__ = df_all_v3.copy()\n",
    "    func = partial(missing_imputation, df__, unique_grup, unique_sku)\n",
    "    #func = partial(missing_imputation_v2, df__, unique_grup, unique_sku)\n",
    "    loop = list(unique_list.index)\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        df_all_v4.append(p.map(func, loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Imputation: 0:00:32.818623\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Missing Imputation: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v4 = pd.concat(df_all_v4[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v4[\"koli_new\"].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfgr = [v.reset_index(drop=True).sort_values(['yil', 'ay']) for k, v in df_all_v3.groupby(['grup_adi'])]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfg={}\n",
    "for grp in range(len(dfgr)):\n",
    "    dfg[dfgr[grp]['grup_adi'].iloc[0]] = dfgr[grp]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def filling2(grup): #aynı aylarla doldurmak\n",
    "    concat = []\n",
    "    for i in list(set(dfg[grup]['en_guncel_kod'])):\n",
    "        dfs = dfg[grup][dfg[grup]['en_guncel_kod']==i].reset_index(drop=True)\n",
    "        df = [v.reset_index(drop=True) for k, v in dfs.groupby(['ay'])]\n",
    "        for i in range(len(df)):\n",
    "            df[i]['koli_new'].fillna(df[i]['koli'].mean(), inplace=True)\n",
    "        updf = pd.concat(df, axis=0).sort_values(['yil', 'ay'])\n",
    "        updf['ay']=[str(i).zfill(2) for i in updf['ay']]\n",
    "        concat.append(updf)\n",
    "    return (pd.concat(concat).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dsdf = []\n",
    "for grp in list(set(df_all_v3['grup_adi'])):\n",
    "    dsdf.append(filling2(grp))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dsdf = pd.concat(dsdf).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all_v4 = dsdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Trend Seasonality Decomposition with parallel processsing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = df_all_v4.drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\"], ignore_index=True)[[\"grup_adi\", \"en_guncel_kod\"]]\n",
    "unique_grup = unique_list[\"grup_adi\"].to_list()\n",
    "unique_en_guncel_kod = unique_list[\"en_guncel_kod\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v4.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_seasonality_decomp(df__, unique_grup, unique_en_guncel_kod, loop):\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "    import numpy as np\n",
    "    print(\"Başladı ---------->\", unique_grup[loop], unique_en_guncel_kod[loop])\n",
    "    temp_df = df__[(df__[\"en_guncel_kod\"] == unique_en_guncel_kod[loop]) & \n",
    "                   (df__[\"grup_adi\"] == unique_grup[loop])]\n",
    "    if len(temp_df) > 2:\n",
    "        df_ts = temp_df[['koli_new','date']]\n",
    "        df_ts.set_index('date',inplace=True)\n",
    "\n",
    "        result = STL(df_ts).fit()\n",
    "        temp_df['season'] = list(result.seasonal)\n",
    "        temp_df['trend']  = list(result.trend)\n",
    "        temp_df['residual']  = list(result.resid)\n",
    "    else:\n",
    "        temp_df['season'] = np.nan\n",
    "        temp_df['trend']  = np.nan\n",
    "        temp_df['residual']  = np.nan\n",
    "    print(\"Bitti ---------->\", unique_grup[loop], unique_en_guncel_kod[loop])\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v5 = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    df__ = df_all_v4.copy()\n",
    "    func = partial(trend_seasonality_decomp, df__, unique_grup, unique_en_guncel_kod)\n",
    "    loop = list(unique_list.index)\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        df_all_v5.append(p.map(func, loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataların yüklenmesi: 0:00:39.316086\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dataların yüklenmesi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v5 = pd.concat(df_all_v5[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all_v5.to_csv(\"../data/pasifik_\"+str(params_[\"time_info_for_debugging\"][\"yil\"])+\"_\"+str(params_[\"time_info_for_debugging\"][\"ay\"])+\"_01_data_to_analysis_koli.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_next_four = df_all_v5[[\"grup_adi\", \"en_guncel_kod\", \"fiyat\", \"date\"]]\n",
    "fiyat_next_four.sort_values(by=[\"grup_adi\", \"en_guncel_kod\", \"date\"], ascending=[True, True, False], inplace=True, ignore_index=True)\n",
    "fiyat_next_four = fiyat_next_four.groupby([\"grup_adi\", \"en_guncel_kod\"]).agg({\"date\": \"max\", \"fiyat\": \"max\"}).reset_index()\n",
    "fiyat_next_four = fiyat_next_four[[\"grup_adi\", \"en_guncel_kod\", \"fiyat\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Scope Belirleme (24 aylık veri varsa time series çalışsın. Yoksa moving average)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scope(df__, unique_grup, unique_sku, threshold, loop):\n",
    "    print(\"Başla ----->\", loop)\n",
    "    tmp = df__[(df__[\"grup_adi\"] == unique_grup[loop]) & (df__[\"en_guncel_kod\"] == unique_sku[loop])]\n",
    "    if len(tmp[tmp[\"koli\"] != 0]) >= 24:\n",
    "        tmp[\"scope\"] = \"time_series\"\n",
    "    else:\n",
    "        tmp[\"scope\"] = \"moving_average\"\n",
    "    print(\"Bitti ----->\", loop)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = df_all_v5[[\"grup_adi\", \"en_guncel_kod\"]].drop_duplicates(ignore_index=True)\n",
    "unique_grup = unique_list[\"grup_adi\"].to_list()\n",
    "unique_sku = unique_list[\"en_guncel_kod\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v6 = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    df__ = df_all_v5.copy()\n",
    "    func = partial(scope, df__, unique_grup, unique_sku, 24)\n",
    "    loop = list(unique_list.index)\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        df_all_v6.append(p.map(func, loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataların yüklenmesi: 0:00:32.519044\n"
     ]
    }
   ],
   "source": [
    "end_time = datetime.now()\n",
    "print('Dataların yüklenmesi: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v6 = pd.concat(df_all_v6[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "kapsam_all.columns = change_col_name(kapsam_all)\n",
    "eslenik_kod_df.columns = change_col_name(eslenik_kod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "kapsam_all[\"urun_kodu\"] = kapsam_all[\"urun_kodu\"].apply(lambda x: int(x.split(\"-\")[0]+x.split(\"-\")[1]))\n",
    "kapsam_all = kapsam_all.merge(eslenik_kod_df[[\"urun_kodu\", \"en_guncel_kod\"]], how=\"left\", on=\"urun_kodu\")\n",
    "kapsam_all[\"en_guncel_kod\"].fillna(kapsam_all[\"urun_kodu\"], inplace=True)\n",
    "kapsam_all.drop_duplicates(subset=[\"en_guncel_kod\", \"grup_adi\"], inplace=True, ignore_index=True)\n",
    "kapsam_all = kapsam_all[kapsam_all[\"en_guncel_kod\"] != \"delist\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted = df_all_v6[df_all_v6[\"Kanal\"] == \"pasifik\"].reset_index(drop=True)\n",
    "df_all_v6 = df_all_v6[df_all_v6[\"Kanal\"] != \"pasifik\"].reset_index(drop=True)\n",
    "pasifik_df_sorted = pasifik_df_sorted.merge(kapsam_all[[\"en_guncel_kod\", \"grup_adi\", \"durum\"]], how=\"left\", on=[\"en_guncel_kod\", \"grup_adi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_write_deneme = list(pasifik_df_sorted[(pasifik_df_sorted[\"durum\"].isna()) & (pasifik_df_sorted[\"grup_adi\"].isin([\"A101\", \"ŞOK\", \"BİM\"]))].index)\n",
    "check = pasifik_df_sorted[(pasifik_df_sorted[\"grup_adi\"] == \"BİM\") & (pasifik_df_sorted[\"portfoy\"] == 1)]\n",
    "check = check[[\"en_guncel_kod\", \"grup_adi\", \"portfoy\", \"durum\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_sorted.loc[idx_to_write_deneme, \"durum\"] = \"DENEME\"\n",
    "df_all_v6[\"durum\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_df_backup_kapsam = pasifik_df_sorted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_scope_index = pasifik_df_sorted[(pasifik_df_sorted[\"portfoy\"] == 1) & \n",
    "                                       (pasifik_df_sorted[\"Kanal\"] == \"pasifik\") & \n",
    "                                       (pasifik_df_sorted[\"durum\"].isin(['DENEME+BÖLGESEL SATIŞ', 'DENEME'])) & \n",
    "                                       (~pasifik_df_sorted[\"grup_adi\"].isin([\"Diğer_Pasifik\", \"MİGROS\"]))].index\n",
    "pasifik_df_sorted.loc[change_scope_index, \"scope\"] = \"kapsam_disi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_sku = pasifik_df_sorted[(pasifik_df_sorted[\"grup_adi\"].isin([\"ŞOK\", \"A101\", \"BİM\"])) & \n",
    "                                        (~(pasifik_df_sorted[\"durum\"].isin([\"Listeli\", \"LİSTELİ\"]))) & \n",
    "                                        (pasifik_df_sorted[\"portfoy\"] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_sku = listeli_olmayan_sku[[\"grup_adi\", \"en_guncel_kod\"]]\n",
    "listeli_olmayan_sku.drop_duplicates(inplace=True, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v6 = pd.concat([pasifik_df_sorted, df_all_v6], ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Historic datanın SAS'a yüklendiği kısım\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sas_upload = df_all_v6.copy()\n",
    "df_sas_upload_date_normal = df_sas_upload.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_koli\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_sas_upload.date.max(), df_sas_upload.date.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    conn.userinfo() \n",
    "except: \n",
    "    print(\"SWAT connections was never created or you lost the connection. Trying to create connection...\") \n",
    "    access_ = True \n",
    "    while access_: \n",
    "        try: \n",
    "            conn = swat.CAS('yhtrcl-sasccnt1.yildiz.domain', 5570, username=params_[\"login_info\"][\"username\"], password=params_[\"login_info\"][\"password\"]) \n",
    "            access_ = False \n",
    "            print(\"Accessed!\") \n",
    "        except:\n",
    "            print(\"Got error. Trying to reconnect...\") \n",
    "            continue\n",
    "\n",
    "df_sas_upload[\"date\"] = df_sas_upload[\"date\"].apply(lambda x: (x - datetime(1960, 1, 1)).days) \n",
    "#ds_table = conn.CASTable('data_'+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_koli\", caslib=params_['caslib_info']['caslib_name'], replace=True) \n",
    "#ds_table.table.dropTable(quiet=True) \n",
    "if conn.table.tableExists(name='data_'+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_koli\",caslib=params_['caslib_info']['caslib_name']).exists:\n",
    "    conn.table.dropTable(name='data_'+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_koli\",caslib=params_['caslib_info']['caslib_name'])\n",
    "conn.upload(data=df_sas_upload, casout={'caslib':params_['caslib_info']['caslib_name'], 'name':'data_'+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_koli\", 'promote':True},  \n",
    "            importoptions={'vars':{'date':{'format': 'MMDDYY', \"type\": \"double\", \"length\": 10}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sas_upload_date_normal[\"datanin_kesildigi_tarih\"] = datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data is inserted into DS_HISTORY_DATA table.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "#    create_connection(r\"../data/db/\"+params_[\"db_info\"][\"db_name\"]+\".sqlite\") # creates new database if there is no db.\n",
    "#    create_new_table(all_final_preds11, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"current_results_table\"]) # creates new table if there is no table.\n",
    "#    upload_new_results(all_final_preds11, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"current_results_table\"]) # drop previous predictions and uploads new predictions for current period.\n",
    "    \n",
    "    update_table(df_sas_upload_date_normal, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"historic_data\"]) # inserts to historic database."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conn = sqlite3.connect(\"../data/db/DS_DATABASE.sqlite\")\n",
    "t = pd.read_sql_query(f\"SELECT * FROM DS_HISTORY_DATA\", con=conn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#sql = 'SELECT * FROM DS_HISTORY_DATA WHERE datanin_kesildigi_tarih is null'\n",
    "sql = \"DELETE FROM DS_HISTORY_DATA WHERE datanin_kesildigi_tarih is null\"\n",
    "cur = conn.cursor()\n",
    "cur.execute(sql)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "# ÖNCE SASTAKİ SONUÇLARIN ÇALIŞMASI GEREKİYOR. SONRA AŞAĞIYI ÇALIŞTIRMAYA BAŞLA!\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAS'tan sonuçları çekme işlemi\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWAT connections was never created or you lost the connection. Trying to create connection...\n",
      "Accessed!\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    conn.userinfo() \n",
    "except: \n",
    "    print(\"SWAT connections was never created or you lost the connection. Trying to create connection...\") \n",
    "    access_ = True \n",
    "    while access_: \n",
    "        try: \n",
    "            conn = swat.CAS('yhtrcl-sasccnt1.yildiz.domain', 5570, username=params_[\"login_info\"][\"username\"], password=params_[\"login_info\"][\"password\"]) \n",
    "            access_ = False \n",
    "            print(\"Accessed!\")\n",
    "            outfor = pd.DataFrame(conn.CASTable(caslib=params_[\"caslib_info\"][\"caslib_name\"],name=params_[\"sas_results\"][\"result_table_name\"]).to_frame())\n",
    "#            outfor = outfor[[\"Kanal\", \"grup_adi\", \"urun_adi\", \"date\", \"ACTUAL\", \"PREDICT\"]]\n",
    "#            outfor[\"date\"] = pd.to_datetime(outfor[\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "        except:\n",
    "            print(\"Got error. Trying to reconnect...\") \n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonuçları notebook hata çıkarırsa diye kaydediyorum\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2022, 6, 1), datetime.date(2022, 5, 1),\n",
       "       datetime.date(2022, 3, 1), datetime.date(2022, 4, 1)], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfor.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor.to_csv(f'sas_results_{data_name_dict[ay_threshold+1]}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirim_dict = {\n",
    "    \n",
    "    0: \"0\",\n",
    "    1: \"%0 - %1\",\n",
    "    2: \"%1 - %2\",\n",
    "    3: \"%2 - %3\",\n",
    "    4: \"%3 - %4\",\n",
    "    5: \"%4 - %5\",\n",
    "    6: \"%5 - %6\",\n",
    "    7: \"%6 - %7\",\n",
    "    8: \"%7 - %8\",\n",
    "    9: \"%8 - %9\",\n",
    "    10: \"%9 - %10\",\n",
    "    11: \"%10 - %15\",\n",
    "    12: \"%15 - max\"\n",
    "}\n",
    "\n",
    "indirim_dict2 = {\n",
    "    \n",
    "    0: '0',\n",
    "    1: '%0 - %1',\n",
    "    2: '%1 - %2',\n",
    "    3: '%2 - %3',\n",
    "    4: '%3 - %4',\n",
    "    5: '%4 - %5',\n",
    "    6: '%5 - %6',\n",
    "    7: '%6 - %7',\n",
    "    8: '%7 - %8',\n",
    "    9: '%8 - %9',\n",
    "    10: '%9 - %10',\n",
    "    12.5: '%10 - %15',\n",
    "    15: '%15 - max'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bu aşağıdaki sütunlar DWH'a yüklememiz için olması gerekiyor. Gerçekleşenler olmadığı için 0 yazıyorum. Tahmin sapması için de 0 diyorum çünkü gelecek ayların gerçekleşenlerini bilmiyoruz.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor[\"gerceklesen_satis_adedi\"] = 0\n",
    "outfor[\"gerceklesen_koli\"] = 0\n",
    "outfor[\"tahmin_sapmasi\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor[\"en_guncel_kod\"] = outfor[\"en_guncel_kod\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_sku_unique = outfor[[\"en_guncel_kod\", \"grup_adi\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outfor2 = []\n",
    "for index in grup_sku_unique.index:\n",
    "    tmp = outfor[(outfor[\"en_guncel_kod\"] == grup_sku_unique.loc[index, \"en_guncel_kod\"]) & (outfor[\"grup_adi\"] == grup_sku_unique.loc[index, \"grup_adi\"])]\n",
    "    tmp[\"datanin_etiketlendigi_algorit\"] = \"time_series\"\n",
    "    if tmp.iloc[0][\"winner_prediction\"] == tmp.iloc[0][\"autoforecast_predict\"]:\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"autoforecast\"\n",
    "        tmp[\"mape\"] = tmp.iloc[0][\"autoforecast_mape\"]\n",
    "    else:\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"moving_average3\"\n",
    "        tmp[\"mape\"] = tmp.iloc[0][\"ma3_mape\"]\n",
    "    outfor2.append(tmp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "outfor2 = pd.concat(outfor2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor2 = outfor.copy()\n",
    "outfor2[\"winner_model\"] = outfor2[\"winner_model\"].apply(lambda x: \"autoforecast\" if x == \"AF\" else(\n",
    "                                                                    'moving_average' if x == 'MA3' else(\n",
    "                                                                        'hierarchical_forecast' if x.startswith('HF') else x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'DIAG1_UCM1', 'DIAG1_REGARIMA1', 'DIAG1_ARIMAX1', 'naiveModel',\n",
       "       'ESMBEST', 'DIAG1_ESM1', 'DIAG1_IDM1'], dtype=object)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfor2.winner_model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor2 = outfor2[['en_guncel_kod', 'grup_adi', 'winner_prediction', 'min_mape', 'winner_model', 'date', \n",
    "                   'aktivite_tipi', 'indirim_yuzdesi','gerceklesen_satis_adedi','gerceklesen_koli','tahmin_sapmasi']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grup adı, ana kategori, kategori, marka isimlerini left join ile getiriyoruz.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_ana_kat_kat_marka_list = df_all_v6[[\"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\", \"en_guncel_kod\"]].drop_duplicates(ignore_index=True)\n",
    "outfor3 = outfor2.merge(kanal_ana_kat_kat_marka_list, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209924, 11), (209924, 15))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfor2.shape, outfor3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_kanal_dict = {\n",
    "    \n",
    "    'A101': 'pasifik', \n",
    "    'BİM': 'pasifik', \n",
    "    'Diğer_Pasifik': 'pasifik', \n",
    "    'MİGROS': 'pasifik', \n",
    "    'ŞOK': 'pasifik', \n",
    "    'Diğer_Horizon': 'horizon', \n",
    "    'GELENEKSEL KANAL': 'horizon', \n",
    "    'ORTA MARKET': 'horizon', \n",
    "    'POTANSİYEL MARKET': 'horizon', \n",
    "    'YEREL ZİNCİR': 'horizon', \n",
    "    'BTT': 'btt'\n",
    "                    \n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Listeli Olmayan Sonuçların Getirilmesi\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df = listeli_olmayan_sku.copy()\n",
    "listeli_olmayan_df[\"Kanal\"] = listeli_olmayan_df[\"grup_adi\"].map(grup_kanal_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comb_listeli_olmayan(excels):\n",
    "#    month_ = datetime.now().month\n",
    "#    year_ = datetime.now().year\n",
    "    month_ = params_[\"time_info_for_debugging\"][\"ay\"]\n",
    "    year_ = params_[\"time_info_for_debugging\"][\"yil\"]\n",
    "    pas_s=list(itertools.product([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12.5, 15],['Yok', 'Mağaza içi/Dağılım', 'İn&out', 'Mutluluk', 'Çoklu Alım', 'Kasiyer', 'CRM']))\n",
    "    diger_s=list(itertools.product([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12.5, 15],[\"Yok\"]))\n",
    "    df_all__=[]\n",
    "    for i in excels.index:\n",
    "        tmp_=pd.DataFrame(excels.loc[i]).T\n",
    "        new_date = datetime(year_, month_, 1)\n",
    "        if tmp_['Kanal'].values[0]=='pasifik':\n",
    "            for trh in range(1, 5):\n",
    "                new_date_ = new_date + relativedelta(months=trh)\n",
    "                create_new = pd.DataFrame(tmp_.iloc[-1])\n",
    "                create_new.loc[\"tarih\"] = datetime(new_date_.year, new_date_.month, 1)\n",
    "                tmp = pd.concat([create_new.T]*len(pas_s), ignore_index=True)\n",
    "                for j in range(len(pas_s)):\n",
    "                    tmp.loc[j,'indirim_yuzdesi'] = pas_s[j][0]\n",
    "                    tmp.loc[j,'aktivite_tipi'] = pas_s[j][1]\n",
    "                df_all__.append(tmp)\n",
    "        else:\n",
    "            for trh in range(1, 5):\n",
    "                new_date_ = new_date + relativedelta(months=trh)\n",
    "                create_new = pd.DataFrame(tmp_.iloc[-1])\n",
    "                create_new.loc[\"tarih\"] = datetime(new_date_.year, new_date_.month, 1)\n",
    "                tmp = pd.concat([create_new.T]*len(diger_s), ignore_index=True)\n",
    "                for k in range(len(diger_s)):\n",
    "                    tmp.loc[k,'indirim_yuzdesi'] = diger_s[k][0]\n",
    "                    tmp.loc[k,'aktivite_tipi'] = diger_s[k][1]\n",
    "                df_all__.append(tmp)\n",
    "    df_all__ = pd.concat(df_all__, ignore_index=True)\n",
    "    return df_all__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df2 = create_comb_listeli_olmayan(listeli_olmayan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3 = listeli_olmayan_df2.copy()\n",
    "listeli_olmayan_sku_list = listeli_olmayan_df2[~(listeli_olmayan_df2[\"aktivite_tipi\"] == \"Yok\")]\n",
    "listeli_olmayan_df3[\"pred\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_2_date = df_all_v6.date.max() + relativedelta(months=2)\n",
    "for idx in listeli_olmayan_sku_list.index:\n",
    "    tmp_hist = df_all[(df_all[\"grup_adi\"] == listeli_olmayan_sku_list.loc[idx, \"grup_adi\"]) & \n",
    "                      (df_all[\"en_guncel_kod\"] == listeli_olmayan_sku_list.loc[idx, \"en_guncel_kod\"]) & \n",
    "                      (df_all[\"aktivite_tipi\"] == listeli_olmayan_sku_list.loc[idx, \"aktivite_tipi\"])]\n",
    "    if len(tmp_hist) > 0:\n",
    "        mean_ = tmp_hist.koli.mean()\n",
    "        keep_index = listeli_olmayan_df3[(listeli_olmayan_df3[\"grup_adi\"] == listeli_olmayan_sku_list.loc[idx, \"grup_adi\"]) & \n",
    "                                         (listeli_olmayan_df3[\"en_guncel_kod\"] == listeli_olmayan_sku_list.loc[idx, \"en_guncel_kod\"]) & \n",
    "                                         (listeli_olmayan_df3[\"aktivite_tipi\"] == listeli_olmayan_sku_list.loc[idx, \"aktivite_tipi\"]) & \n",
    "                                         (listeli_olmayan_df3[\"tarih\"] == t_2_date)].index\n",
    "\n",
    "        listeli_olmayan_df3.loc[keep_index, \"pred\"] = mean_\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3.pred.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3[\"del_col\"] = listeli_olmayan_df3[\"grup_adi\"].astype(str) + \"_\" + listeli_olmayan_df3[\"en_guncel_kod\"].astype(str)\n",
    "listeli_olmayan_df3[\"akt_ind_check\"] = listeli_olmayan_df3[\"aktivite_tipi\"].astype(str) + \"_\" + listeli_olmayan_df3[\"indirim_yuzdesi\"].astype(str)\n",
    "listeli_olmayan_df3[\"type\"] = \"listeli_olmayan_sku\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3.rename(columns={\"tarih\": \"date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3[\"indirim_yuzdesi\"] = listeli_olmayan_df3[\"indirim_yuzdesi\"].map(indirim_dict2)\n",
    "listeli_olmayan_df3.drop(columns=[\"del_col\", \"akt_ind_check\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sas sonuçlarından işimize yaramayan sütunları çıkartıyoruz\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3.rename(columns={\"pred\": \"tahmin_koli\", \"type\": \"tahmin_edilme_yontemi\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3[\"datanin_etiketlendigi_algorit\"] = listeli_olmayan_df3[\"tahmin_edilme_yontemi\"]\n",
    "listeli_olmayan_df3[\"gerceklesen_koli\"] = 0\n",
    "listeli_olmayan_df3[\"gerceklesen_satis_adedi\"] = 0\n",
    "listeli_olmayan_df3[\"mape\"] = 0\n",
    "listeli_olmayan_df3[\"tahmin_sapmasi\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_df3 = listeli_olmayan_df3.merge(kanal_ana_kat_kat_marka_list, how=\"left\")\n",
    "#listeli_olmayan_df3 = listeli_olmayan_df3[outfor3.columns.to_list()]\n",
    "listeli_olmayan_df3 = listeli_olmayan_df3[['en_guncel_kod','grup_adi','tahmin_koli','tahmin_sapmasi','tahmin_edilme_yontemi','date',\n",
    "                                           'Kanal','ana_kategori_adi','kategori_adi','marka_adi','indirim_yuzdesi','aktivite_tipi',\n",
    "                                           'mape','gerceklesen_koli','gerceklesen_satis_adedi']]\n",
    "#Alttaki cell üste alınıp bu cell'deki 2. satır açılıp 3. satır silinebilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outfor3.drop(columns=[\"indirim\", \"aktivite\", \"dolu_gozlem\", \"toplam_gozlem\", \"autoforecast_mape\", \"ma3_mape\", \"autoforecast_predict\", \"ma3_predict\"], axis=1, inplace=True)\n",
    "outfor3.rename(columns={\"winner_prediction\": \"tahmin_koli\", \"min_mape\": \"mape\", \"winner_model\": \"tahmin_edilme_yontemi\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_guncel_kod</th>\n",
       "      <th>grup_adi</th>\n",
       "      <th>tahmin_koli</th>\n",
       "      <th>mape</th>\n",
       "      <th>tahmin_edilme_yontemi</th>\n",
       "      <th>date</th>\n",
       "      <th>aktivite_tipi</th>\n",
       "      <th>indirim_yuzdesi</th>\n",
       "      <th>gerceklesen_satis_adedi</th>\n",
       "      <th>gerceklesen_koli</th>\n",
       "      <th>tahmin_sapmasi</th>\n",
       "      <th>Kanal</th>\n",
       "      <th>ana_kategori_adi</th>\n",
       "      <th>kategori_adi</th>\n",
       "      <th>marka_adi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103304</td>\n",
       "      <td>A101</td>\n",
       "      <td>11574.5</td>\n",
       "      <td>7.212388</td>\n",
       "      <td></td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>CRM</td>\n",
       "      <td>%2 - %3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>KEK</td>\n",
       "      <td>DANKEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103304</td>\n",
       "      <td>A101</td>\n",
       "      <td>11574.5</td>\n",
       "      <td>7.212388</td>\n",
       "      <td></td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Yok</td>\n",
       "      <td>%1 - %2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>KEK</td>\n",
       "      <td>DANKEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103304</td>\n",
       "      <td>A101</td>\n",
       "      <td>11574.5</td>\n",
       "      <td>7.212388</td>\n",
       "      <td></td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Mutluluk</td>\n",
       "      <td>%1 - %2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>KEK</td>\n",
       "      <td>DANKEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103304</td>\n",
       "      <td>A101</td>\n",
       "      <td>11574.5</td>\n",
       "      <td>7.212388</td>\n",
       "      <td></td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Çoklu Alım</td>\n",
       "      <td>%2 - %3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>KEK</td>\n",
       "      <td>DANKEK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103304</td>\n",
       "      <td>A101</td>\n",
       "      <td>11574.5</td>\n",
       "      <td>7.212388</td>\n",
       "      <td></td>\n",
       "      <td>2022-05-01</td>\n",
       "      <td>Kasiyer</td>\n",
       "      <td>%4 - %5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>KEK</td>\n",
       "      <td>DANKEK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  en_guncel_kod grup_adi  tahmin_koli      mape tahmin_edilme_yontemi  \\\n",
       "0        103304     A101      11574.5  7.212388                         \n",
       "1        103304     A101      11574.5  7.212388                         \n",
       "2        103304     A101      11574.5  7.212388                         \n",
       "3        103304     A101      11574.5  7.212388                         \n",
       "4        103304     A101      11574.5  7.212388                         \n",
       "\n",
       "         date aktivite_tipi indirim_yuzdesi  gerceklesen_satis_adedi  \\\n",
       "0  2022-06-01           CRM         %2 - %3                        0   \n",
       "1  2022-06-01           Yok         %1 - %2                        0   \n",
       "2  2022-06-01      Mutluluk         %1 - %2                        0   \n",
       "3  2022-06-01    Çoklu Alım         %2 - %3                        0   \n",
       "4  2022-05-01       Kasiyer         %4 - %5                        0   \n",
       "\n",
       "   gerceklesen_koli  tahmin_sapmasi    Kanal ana_kategori_adi kategori_adi  \\\n",
       "0                 0               0  pasifik     ATIŞTIRMALIK          KEK   \n",
       "1                 0               0  pasifik     ATIŞTIRMALIK          KEK   \n",
       "2                 0               0  pasifik     ATIŞTIRMALIK          KEK   \n",
       "3                 0               0  pasifik     ATIŞTIRMALIK          KEK   \n",
       "4                 0               0  pasifik     ATIŞTIRMALIK          KEK   \n",
       "\n",
       "  marka_adi  \n",
       "0    DANKEK  \n",
       "1    DANKEK  \n",
       "2    DANKEK  \n",
       "3    DANKEK  \n",
       "4    DANKEK  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfor3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor4 = outfor3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_olmayan_sku[\"grup_sku\"] = listeli_olmayan_sku[\"grup_adi\"] + \"_\" + listeli_olmayan_sku[\"en_guncel_kod\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listeli olmayan ürünlerin sonuçları SAS'ta da bulunuyor. O yüzden iki kısımda da prediction'ı var gibi bir durum söz konusu. SAS sonuçlarından listeli olmaynaları çıkartıyoruz.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor5 = []\n",
    "check_list = listeli_olmayan_sku[\"grup_sku\"].to_list()\n",
    "for index in grup_sku_unique.index:\n",
    "    tmp = outfor4[(outfor4[\"grup_adi\"] == grup_sku_unique.loc[index, \"grup_adi\"]) & \n",
    "                  (outfor4[\"en_guncel_kod\"] == grup_sku_unique.loc[index, \"en_guncel_kod\"])]\n",
    "    if tmp.iloc[0][\"grup_adi\"] + \"_\" + str(tmp.iloc[0][\"en_guncel_kod\"]) in check_list:\n",
    "        pass\n",
    "    else:\n",
    "        outfor5.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor5 = pd.concat(outfor5, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TÜM BİRLEŞTİRİLMİŞ SONUÇLAR\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor5_backup = outfor5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfor5.date = pd.to_datetime(outfor5.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6 = pd.concat([outfor5, listeli_olmayan_df3], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "check__2 = all_final_preds6.groupby([\"date\", \"Kanal\", \"grup_adi\", \"en_guncel_kod\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "urun_isimleri = eslenik_kod_df[[\"urun_kodu\", \"urun_adi_orjinal\"]]\n",
    "urun_isimleri.rename(columns={\"urun_kodu\": \"en_guncel_kod\", \"urun_adi_orjinal\": \"urun_adi\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_dwh = {\n",
    "    \n",
    "    \"date\": \"TARIH\",\n",
    "    \"Kanal\": \"KANAL\",\n",
    "    \"grup_adi\": \"GRUP_ADI\",\n",
    "    \"ana_kategori_adi\": \"ANA_KATEGORI_ADI\",\n",
    "    \"kategori_adi\": \"KATEGORI_ADI\",\n",
    "    \"marka_adi\": \"MARKA_ADI\",\n",
    "    \"urun_adi\": \"URUN_ADI\",\n",
    "    \"en_guncel_kod\": \"EN_GUNCEL_KOD\",\n",
    "    \"gerceklesen_satis_adedi\": \"GERCEKLESEN_SATIS_ADEDI\",\n",
    "    \"tahmin_adet\": \"TAHMIN_ADET\",\n",
    "    \"tahmin_ust_sinir\": \"TAHMIN_UST_SINIR\",\n",
    "    \"tahmin_alt_sinir\": \"TAHMIN_ALT_SINIR\",\n",
    "    \"koli_ici_adet\": \"KOLI_ICI_ADET\",\n",
    "    \"tahmin_koli\": \"TAHMIN_KOLI\",\n",
    "    \"mape\": \"MAPE\",\n",
    "    \"gerceklesen_koli\": \"GERCEKLESEN_KOLI\",\n",
    "    \"indirim_yuzdesi\": \"INDIRIM_YUZDESI\",\n",
    "    \"aktivite_tipi\": \"AKTIVITE_TIPI\",\n",
    "    \"tahmin_edilme_yontemi\": \"TAHMIN_EDILME_YONTEMI\",\n",
    "    \"datanin_etiketlendigi_algorit\": \"DATANIN_ETIKETLENDIGI_ALGORIT\",\n",
    "    \"tahmin_sapmasi\": \"TAHMIN_SAPMASI\",\n",
    "    \"tl_unit\": \"TL_UNIT\",\n",
    "    \"kg_unit\": \"KG_UNIT\",\n",
    "    \"kg\": \"KG\",\n",
    "    \"tl\": \"TL\",\n",
    "    \"tahmin_koli_alt_sinir\": \"TAHMIN_KOLI_ALT_SINIR\",\n",
    "    \"tahmin_koli_ust_sinir\": \"TAHMIN_KOLI_UST_SINIR\",\n",
    "    \"aktivite_etkisi\": \"AKTIVITE_ETKISI\"\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name_dwh_order = [i for i in col_name_dwh.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6.tahmin_koli.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6[\"mape_regulation\"] = all_final_preds6[\"mape\"].apply(lambda x: 100 if x>100 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6[\"tahmin_koli_alt_sinir\"] = all_final_preds6[\"tahmin_koli\"] - (all_final_preds6[\"tahmin_koli\"]*(all_final_preds6[\"mape\"] / 100))\n",
    "all_final_preds6[\"tahmin_koli_ust_sinir\"] = all_final_preds6[\"tahmin_koli\"] + (all_final_preds6[\"tahmin_koli\"]*(all_final_preds6[\"mape\"] / 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_unique_list = fiyat_unique[[\"Kanal\", \"en_guncel_kod\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiyat_guncel_calculate(fiyat_unique, fiyat_unique_list, idx):\n",
    "    print(\"Basladı -->\", idx)\n",
    "    tmp = fiyat_unique[(fiyat_unique[\"Kanal\"] == fiyat_unique_list.loc[idx, \"Kanal\"]) & \n",
    "                       (fiyat_unique[\"en_guncel_kod\"] == fiyat_unique_list.loc[idx, \"en_guncel_kod\"])]\n",
    "    tmp = tmp[tmp[\"date\"] == tmp[\"date\"].max()]\n",
    "    print(\"Bitti -->\", idx)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_guncel = []\n",
    "if __name__ == \"__main__\" or __name__ == \"__parents_main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    func = partial(fiyat_guncel_calculate, fiyat_unique, fiyat_unique_list)\n",
    "    loop = list(fiyat_unique_list.index)\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        fiyat_guncel.append(p.map(func, loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_guncel = pd.concat(fiyat_guncel[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiyat_guncel_btt = fiyat_guncel[fiyat_guncel[\"Kanal\"] == \"horizon\"]\n",
    "fiyat_guncel_btt[\"Kanal\"] = \"btt\"\n",
    "fiyat_guncel = pd.concat([fiyat_guncel, fiyat_guncel_btt], ignore_index=True, axis=0)\n",
    "fiyat_guncel.rename(columns={\"fiyat\": \"tl_unit\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 18)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6 = all_final_preds6.merge(fiyat_guncel[[\"Kanal\", \"en_guncel_kod\", \"tl_unit\"]], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 19)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6[\"tl\"] = all_final_preds6[\"tahmin_koli\"] * all_final_preds6[\"tl_unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6.drop(\"mape_regulation\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_birim_agirlik.rename(columns={\"kanal\": \"Kanal\", \"kg\": \"kg_unit\"}, inplace=True)\n",
    "koli_birim_agirlik = koli_birim_agirlik[[\"Kanal\", \"en_guncel_kod\", \"kg_unit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 19)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6 = all_final_preds6.merge(koli_birim_agirlik, how=\"left\")\n",
    "all_final_preds6.kg_unit.fillna(0, inplace=True)\n",
    "all_final_preds6[\"kg\"] = all_final_preds6[\"kg_unit\"] * all_final_preds6[\"tahmin_koli\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 21)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_unique = koli_ici_adet_all[~(koli_ici_adet_all[\"grup_adi\"].isin(['A101', 'BİM', 'Diğer_Pasifik', 'ŞOK', 'MİGROS']))][[\"grup_adi\", \"en_guncel_kod\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def koli_ici_adet_calculate(koli_ici_adet_all, koli_ici_adet_unique, idx):\n",
    "    print(\"Basladı -->\", idx)\n",
    "    tmp = koli_ici_adet_all[(koli_ici_adet_all[\"grup_adi\"] == koli_ici_adet_unique.loc[idx, \"grup_adi\"]) & \n",
    "                            (koli_ici_adet_all[\"en_guncel_kod\"] == koli_ici_adet_unique.loc[idx, \"en_guncel_kod\"])]\n",
    "    tmp = tmp[tmp[\"tarih\"] == tmp[\"tarih\"].max()]\n",
    "    print(\"Bitti -->\", idx)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_all2 = []\n",
    "if __name__ == \"__main__\" or __name__ == \"__parents_main__\":\n",
    "    mp.freeze_support()\n",
    "    available_cpu = mp.cpu_count() - 1\n",
    "    func = partial(koli_ici_adet_calculate, koli_ici_adet_all, koli_ici_adet_unique)\n",
    "    loop = list(koli_ici_adet_unique.index)\n",
    "    with mp.Pool(available_cpu) as p:\n",
    "        koli_ici_adet_all2.append(p.map(func, loop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_all2 = pd.concat(koli_ici_adet_all2[0], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_all3 = pd.concat([koli_ici_adet_all2, koli_ici_adet_all[koli_ici_adet_all.grup_adi.isin([\"A101\", \"BİM\", \"Diğer_Pasifik\", \"MİGROS\", \"ŞOK\"])]], ignore_index=True, axis=0)\n",
    "koli_ici_adet_all3.drop(\"tarih\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "koli_ici_adet_all3.drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\"], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 21)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6 = all_final_preds6.merge(koli_ici_adet_all3, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 22)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6_backup = all_final_preds6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6[\"tahmin_adet\"] = all_final_preds6[\"koli_ici_adet\"] * all_final_preds6[\"tahmin_koli\"]\n",
    "all_final_preds6[\"tahmin_ust_sinir\"] = all_final_preds6[\"koli_ici_adet\"] * all_final_preds6[\"tahmin_koli_ust_sinir\"]\n",
    "all_final_preds6[\"tahmin_alt_sinir\"] = all_final_preds6[\"koli_ici_adet\"] * all_final_preds6[\"tahmin_koli_alt_sinir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 25)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6 = all_final_preds6.merge(urun_isimleri, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 26)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6.en_guncel_kod = all_final_preds6.en_guncel_kod.astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6[\"datanin_etiketlendigi_algorit\"] = all_final_preds6[\"tahmin_edilme_yontemi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aktivite_etkisi'}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i for i in col_name_dwh.keys()]) - set(all_final_preds6.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_final_preds6.columns) - set([i for i in col_name_dwh.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6__backup = all_final_preds6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 27)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds6.drop_duplicates(subset=[\"en_guncel_kod\", \"grup_adi\", \"date\", \"aktivite_tipi\", \"indirim_yuzdesi\"], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 27)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds7 = all_final_preds6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasifik_akt_list = list(itertools.product(all_final_preds7.aktivite_tipi.unique(), all_final_preds7.indirim_yuzdesi.unique()))\n",
    "pasifik_akt_list = [str(i[0])+\"_\"+str(i[1]) for i in pasifik_akt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_akt_list = list(itertools.product(all_final_preds7[all_final_preds7[\"Kanal\"] != \"pasifik\"].aktivite_tipi.unique(), all_final_preds7.indirim_yuzdesi.unique()))\n",
    "horizon_akt_list = [str(i[0])+\"_\"+str(i[1]) for i in horizon_akt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds8 = all_final_preds7[~((all_final_preds7[\"Kanal\"].isin([\"horizon\", \"btt\"])) & (all_final_preds7[\"aktivite_tipi\"] != \"Yok\"))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds8[\"akt_ind\"] = all_final_preds8[\"aktivite_tipi\"].astype(str) + \"_\" + all_final_preds8[\"indirim_yuzdesi\"].astype(str)\n",
    "all_final_preds8[\"date\"] = pd.to_datetime(all_final_preds8[\"date\"])\n",
    "grup_sku_unique[\"grup_sku\"] = grup_sku_unique[\"grup_adi\"].astype(str) + \"_\" + grup_sku_unique[\"en_guncel_kod\"].astype(str)\n",
    "liseli_haric_grup_list = list(set(grup_sku_unique[\"grup_sku\"]) - set(listeli_olmayan_sku[\"grup_sku\"]))\n",
    "listeli_haric_grup_sku = grup_sku_unique[grup_sku_unique[\"grup_sku\"].isin(liseli_haric_grup_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eğer t+2 haricindeki aylar için kombinasyonlar dönmemiş ise aşağıdaki kısımları çalıştır.\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tarih_list = [i for i in all_final_preds8.date.unique() if i != t_2_date]\n",
    "\n",
    "all_final_preds9 = []\n",
    "for index in listeli_haric_grup_sku.index:\n",
    "    tmp = all_final_preds8[(all_final_preds8[\"grup_adi\"] == listeli_haric_grup_sku.loc[index, \"grup_adi\"]) & \n",
    "                           (all_final_preds8[\"en_guncel_kod\"] == listeli_haric_grup_sku.loc[index, \"en_guncel_kod\"])]\n",
    "    tmp = tmp[tmp[\"date\"].isin(tarih_list)]\n",
    "    tmp.drop_duplicates(subset=[i for i in tmp.columns if i not in [\"tahmin_adet\", \"tahmin_ust_sinir\", \"tahmin_alt_sinir\"]], inplace=True)\n",
    "    for trh_unique in tarih_list:\n",
    "        tmp2 = tmp[tmp[\"date\"] == trh_unique]\n",
    "        if tmp2[\"Kanal\"].unique()[0] == \"pasifik\":\n",
    "            add_row_num = len([i for i in pasifik_akt_list if i not in tmp2[\"akt_ind\"].unique()])\n",
    "            add_akt_list = [i for i in pasifik_akt_list if i not in tmp2[\"akt_ind\"].unique()]\n",
    "        else:\n",
    "            add_row_num = len([i for i in horizon_akt_list if i not in tmp2[\"akt_ind\"].unique()])\n",
    "            add_akt_list = [i for i in horizon_akt_list if i not in tmp2[\"akt_ind\"].unique()]\n",
    "        tmp_to_add = pd.concat([tmp2]*add_row_num)\n",
    "        tmp_to_add[\"akt_ind\"] = add_akt_list\n",
    "        tmp_to_add[\"aktivite_tipi\"] = tmp_to_add[\"akt_ind\"].apply(lambda x: x.split(\"_\")[0])\n",
    "        tmp_to_add[\"indirim_yuzdesi\"] = tmp_to_add[\"akt_ind\"].apply(lambda x: x.split(\"_\")[1])\n",
    "        final = pd.concat([tmp2, tmp_to_add], axis=0)\n",
    "        all_final_preds9.append(final)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeli_olmayan_tekrar_ekle = all_final_preds8[all_final_preds8[\"tahmin_edilme_yontemi\"] == \"listeli_olmayan_sku\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_final_preds9 = pd.concat(all_final_preds9, ignore_index=True)\n",
    "all_final_preds9 = pd.concat([all_final_preds9, listeli_olmayan_tekrar_ekle], ignore_index=True)\n",
    "t_2_datasi = all_final_preds8[all_final_preds8[\"date\"] == t_2_date]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_final_preds9 = pd.concat([all_final_preds9, t_2_datasi], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds9 = all_final_preds8.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds9.to_csv(\"tum_grup_kat_oncesi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_final_preds9.drop(\"akt_ind\", axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 27)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds9.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209924, 27)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds9.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Tüm Grup, Tüm Ana Kategori, Tüm Kategori ve Tüm Marka groupby\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds9[\"from\"] = \"row\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_all = all_final_preds9.groupby([\"date\", \"Kanal\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "kanal_all[\"grup_adi\"] = \"TÜM GRUPLAR\"\n",
    "kanal_all[\"ana_kategori_adi\"] = \"TÜM ANA KATEGORİLER\"\n",
    "kanal_all[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "kanal_all[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "kanal_all[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "kanal_all[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "kanal_all[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "kanal_all[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#kanal_all[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_all[\"from\"] = \"kanal_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_all = all_final_preds9.groupby([\"date\", \"Kanal\", \"grup_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "grup_all[\"ana_kategori_adi\"] = \"TÜM ANA KATEGORİLER\"\n",
    "grup_all[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "grup_all[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "grup_all[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "grup_all[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "grup_all[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "grup_all[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#grup_all[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_all[\"from\"] = \"grup_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_kategori_all = all_final_preds9.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "ana_kategori_all[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "ana_kategori_all[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "ana_kategori_all[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "ana_kategori_all[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "ana_kategori_all[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "ana_kategori_all[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#ana_kategori_all[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_kategori_all[\"from\"] = \"ana_kategori_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "kategori_all = all_final_preds9.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \n",
    "                                         \"kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "\n",
    "kategori_all[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "kategori_all[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "kategori_all[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "kategori_all[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "kategori_all[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#kategori_all[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "kategori_all[\"from\"] = \"kategori_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "marka_all = all_final_preds9.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \n",
    "                                      \"kategori_adi\", \"marka_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "\n",
    "marka_all[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "marka_all[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "marka_all[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "marka_all[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#marka_all[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "marka_all[\"from\"] = \"marka_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiyerarşik detay kırılımları ile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_detail = []\n",
    "for idx in all_final_preds9.grup_adi.unique():\n",
    "    tmp = all_final_preds9[all_final_preds9[\"grup_adi\"] == idx]\n",
    "    tmp = tmp.groupby([\"date\", \"Kanal\", \"grup_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "    tmp[\"ana_kategori_adi\"] = \"TÜM ANA KATEGORİLER\"\n",
    "    tmp[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "    tmp[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "    tmp[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "    tmp[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "    tmp[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "    tmp[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#    tmp[\"aktivite_etkisi\"] = \"Var\"\n",
    "    grup_detail.append(tmp)\n",
    "grup_detail = pd.concat(grup_detail, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_detail[\"from\"] = \"grup_detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_kategori_detail = []\n",
    "for idx in all_final_preds9.ana_kategori_adi.unique():\n",
    "    tmp = all_final_preds9[all_final_preds9[\"ana_kategori_adi\"] == idx]\n",
    "    kontrol = tmp.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).agg({\"kategori_adi\": \"nunique\"}).reset_index().kategori_adi.unique()[0]\n",
    "    tmp = tmp.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "    if kontrol == 1:\n",
    "        pass\n",
    "    else:\n",
    "        tmp[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "        tmp[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "        tmp[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "        tmp[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "        tmp[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#        tmp[\"aktivite_etkisi\"] = \"Var\"\n",
    "        ana_kategori_detail.append(tmp)\n",
    "ana_kategori_detail = pd.concat(ana_kategori_detail, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana_kategori_detail[\"from\"] = \"ana_kategori_detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = all_final_preds9.drop_duplicates(subset=[\"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\"])[[\"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\"]].reset_index(drop=True)\n",
    "kategori_detail = []\n",
    "for idx in liste.index:\n",
    "    tmp = all_final_preds9[(all_final_preds9[\"Kanal\"] == liste[\"Kanal\"][idx]) & \n",
    "                           (all_final_preds9[\"grup_adi\"] == liste[\"grup_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"ana_kategori_adi\"] == liste[\"ana_kategori_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"kategori_adi\"] == liste[\"kategori_adi\"][idx])]\n",
    "    kontrol = len(tmp[\"marka_adi\"].unique())\n",
    "    if kontrol == 1:\n",
    "        pass\n",
    "    else:\n",
    "        tmp = tmp.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "        tmp[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "        tmp[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "        tmp[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "        tmp[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#        tmp[\"aktivite_etkisi\"] = \"Var\"\n",
    "        kategori_detail.append(tmp)\n",
    "kategori_detail = pd.concat(kategori_detail, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "kategori_detail[\"from\"] = \"kategori_detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = all_final_preds9.drop_duplicates(subset=[\"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \n",
    "                                                 \"kategori_adi\", \"marka_adi\"])[[\"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\"]].reset_index(drop=True)\n",
    "marka_detail = []\n",
    "for idx in liste.index:\n",
    "    tmp = all_final_preds9[(all_final_preds9[\"Kanal\"] == liste[\"Kanal\"][idx]) & \n",
    "                           (all_final_preds9[\"grup_adi\"] == liste[\"grup_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"ana_kategori_adi\"] == liste[\"ana_kategori_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"kategori_adi\"] == liste[\"kategori_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"marka_adi\"] == liste[\"marka_adi\"][idx])]\n",
    "    kontrol = len(tmp[\"en_guncel_kod\"].unique())\n",
    "    if kontrol == 1:\n",
    "        pass\n",
    "    else:\n",
    "        tmp = tmp.groupby([\"date\", \"Kanal\", \"grup_adi\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "        tmp[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "        tmp[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "        tmp[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#        tmp[\"aktivite_etkisi\"] = \"Var\"\n",
    "        marka_detail.append(tmp)\n",
    "marka_detail = pd.concat(marka_detail, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "marka_detail[\"from\"] = \"marka_detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_ana_kategori = all_final_preds9.groupby([\"date\", \"Kanal\", \"ana_kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "tum_gruplar_ana_kategori[\"grup_adi\"] = \"TÜM GRUPLAR\"\n",
    "tum_gruplar_ana_kategori[\"kategori_adi\"] = \"TÜM KATEGORİLER\"\n",
    "tum_gruplar_ana_kategori[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "tum_gruplar_ana_kategori[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "tum_gruplar_ana_kategori[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "tum_gruplar_ana_kategori[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "tum_gruplar_ana_kategori[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#tum_gruplar_ana_kategori[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_ana_kategori[\"from\"] = \"tum_gruplar_ana_kategori\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_kategori = all_final_preds9.groupby([\"date\", \"Kanal\", \"ana_kategori_adi\", \"kategori_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "tum_gruplar_kategori[\"grup_adi\"] = \"TÜM GRUPLAR\"\n",
    "tum_gruplar_kategori[\"marka_adi\"] = \"TÜM MARKALAR\"\n",
    "tum_gruplar_kategori[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "tum_gruplar_kategori[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "tum_gruplar_kategori[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "tum_gruplar_kategori[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#tum_gruplar_kategori[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_kategori[\"from\"] = \"tum_gruplar_kategori\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = all_final_preds9.drop_duplicates(subset=[\"Kanal\", \"ana_kategori_adi\", \n",
    "                                                 \"kategori_adi\", \"marka_adi\"])[[\"Kanal\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_marka = []\n",
    "for idx in liste.index:\n",
    "    tmp = all_final_preds9[(all_final_preds9[\"Kanal\"] == liste[\"Kanal\"][idx]) & \n",
    "                           (all_final_preds9[\"ana_kategori_adi\"] == liste[\"ana_kategori_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"kategori_adi\"] == liste[\"kategori_adi\"][idx]) & \n",
    "                           (all_final_preds9[\"marka_adi\"] == liste[\"marka_adi\"][idx])]\n",
    "    kontrol = len(tmp[\"en_guncel_kod\"].unique())\n",
    "    if kontrol == 1:\n",
    "        pass\n",
    "    else:\n",
    "        tmp = tmp.groupby([\"date\", \"Kanal\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "        tmp[\"grup_adi\"] = \"TÜM GRUPLAR\"\n",
    "        tmp[\"en_guncel_kod\"] = \"TÜM SKULAR\"\n",
    "        tmp[\"urun_adi\"] = \"TÜM ÜRÜNLER\"\n",
    "        tmp[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "        tmp[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#        tmp[\"aktivite_etkisi\"] = \"Var\"\n",
    "        tum_gruplar_marka.append(tmp)\n",
    "tum_gruplar_marka = pd.concat(tum_gruplar_marka, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_marka[\"from\"] = \"tum_gruplar_marka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_en_guncel_kod = all_final_preds9.groupby([\"date\", \"Kanal\", \"ana_kategori_adi\", \"kategori_adi\", \"marka_adi\", \"en_guncel_kod\", \"urun_adi\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).sum().reset_index()\n",
    "tum_gruplar_en_guncel_kod[\"grup_adi\"] = \"TÜM GRUPLAR\"\n",
    "tum_gruplar_en_guncel_kod[\"tahmin_edilme_yontemi\"] = \"N/A\"\n",
    "tum_gruplar_en_guncel_kod[\"datanin_etiketlendigi_algorit\"] = \"N/A\"\n",
    "#tum_gruplar_en_guncel_kod[\"aktivite_etkisi\"] = \"Var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "tum_gruplar_en_guncel_kod[\"from\"] = \"tum_gruplar_en_guncel_kod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = all_final_preds9.groupby([\"grup_adi\", \"en_guncel_kod\", \"date\", \"indirim_yuzdesi\", \"aktivite_tipi\"]).count().reset_index()\n",
    "kntrl = chk[chk[\"Kanal\"] > 1].drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\", \"date\", \"indirim_yuzdesi\", \"aktivite_tipi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boş gelmesi doğru olduğuna işaret ediyor\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grup_adi</th>\n",
       "      <th>en_guncel_kod</th>\n",
       "      <th>date</th>\n",
       "      <th>indirim_yuzdesi</th>\n",
       "      <th>aktivite_tipi</th>\n",
       "      <th>tahmin_koli</th>\n",
       "      <th>mape</th>\n",
       "      <th>tahmin_edilme_yontemi</th>\n",
       "      <th>gerceklesen_satis_adedi</th>\n",
       "      <th>gerceklesen_koli</th>\n",
       "      <th>tahmin_sapmasi</th>\n",
       "      <th>Kanal</th>\n",
       "      <th>ana_kategori_adi</th>\n",
       "      <th>kategori_adi</th>\n",
       "      <th>marka_adi</th>\n",
       "      <th>tahmin_koli_alt_sinir</th>\n",
       "      <th>tahmin_koli_ust_sinir</th>\n",
       "      <th>tl_unit</th>\n",
       "      <th>tl</th>\n",
       "      <th>kg_unit</th>\n",
       "      <th>kg</th>\n",
       "      <th>koli_ici_adet</th>\n",
       "      <th>tahmin_adet</th>\n",
       "      <th>tahmin_ust_sinir</th>\n",
       "      <th>tahmin_alt_sinir</th>\n",
       "      <th>urun_adi</th>\n",
       "      <th>datanin_etiketlendigi_algorit</th>\n",
       "      <th>from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [grup_adi, en_guncel_kod, date, indirim_yuzdesi, aktivite_tipi, tahmin_koli, mape, tahmin_edilme_yontemi, gerceklesen_satis_adedi, gerceklesen_koli, tahmin_sapmasi, Kanal, ana_kategori_adi, kategori_adi, marka_adi, tahmin_koli_alt_sinir, tahmin_koli_ust_sinir, tl_unit, tl, kg_unit, kg, koli_ici_adet, tahmin_adet, tahmin_ust_sinir, tahmin_alt_sinir, urun_adi, datanin_etiketlendigi_algorit, from]\n",
       "Index: []"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kntrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "kanal_all = kanal_all[all_final_preds9.columns.to_list()]\n",
    "grup_all = grup_all[all_final_preds9.columns.to_list()]\n",
    "ana_kategori_all = ana_kategori_all[all_final_preds9.columns.to_list()]\n",
    "kategori_all = kategori_all[all_final_preds9.columns.to_list()]\n",
    "marka_all = marka_all[all_final_preds9.columns.to_list()]\n",
    "grup_detail = grup_detail[all_final_preds9.columns.to_list()]\n",
    "ana_kategori_detail = ana_kategori_detail[all_final_preds9.columns.to_list()]\n",
    "kategori_detail = kategori_detail[all_final_preds9.columns.to_list()]\n",
    "marka_detail = marka_detail[all_final_preds9.columns.to_list()]\n",
    "tum_gruplar_ana_kategori = tum_gruplar_ana_kategori[all_final_preds9.columns.to_list()]\n",
    "tum_gruplar_kategori = tum_gruplar_kategori[all_final_preds9.columns.to_list()]\n",
    "tum_gruplar_marka = tum_gruplar_marka[all_final_preds9.columns.to_list()]\n",
    "tum_gruplar_en_guncel_kod = tum_gruplar_en_guncel_kod[all_final_preds9.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10 = pd.concat([all_final_preds9,\n",
    "                              kanal_all,\n",
    "                              grup_all,\n",
    "                              ana_kategori_all,\n",
    "                              kategori_all,\n",
    "                              marka_all,\n",
    "                              grup_detail,\n",
    "                              ana_kategori_detail,\n",
    "                              kategori_detail,\n",
    "                              marka_detail,\n",
    "                              tum_gruplar_ana_kategori,\n",
    "                              tum_gruplar_kategori,\n",
    "                              tum_gruplar_marka,\n",
    "                              tum_gruplar_en_guncel_kod], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10.drop_duplicates(ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10.columns = [i[:-2] if len(i) > 30 else i for i in all_final_preds10.columns]\n",
    "all_final_preds10[\"en_guncel_kod\"] = all_final_preds10[\"en_guncel_kod\"].apply(lambda x: \"TÜM SKULAR\" if x == \"TÜM SKU'LAR\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "grup_and_sku_list = all_final_preds10.drop_duplicates(subset=[\"grup_adi\", \"en_guncel_kod\"], ignore_index=True)[[\"grup_adi\", \"en_guncel_kod\"]]\n",
    "grup_and_sku_list = grup_and_sku_list[grup_and_sku_list[\"en_guncel_kod\"] != \"TÜM SKULAR\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"aktivite_tipi\"] = all_final_preds10[\"aktivite_tipi\"].apply(lambda x: \"In-out\" if x==\"İn&out\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"Kanal\"] = all_final_preds10[\"Kanal\"].str.replace(\"'\", \"\")\n",
    "all_final_preds10[\"grup_adi\"] = all_final_preds10[\"grup_adi\"].str.replace(\"'\", \"\")\n",
    "all_final_preds10[\"ana_kategori_adi\"] = all_final_preds10[\"ana_kategori_adi\"].str.replace(\"'\", \"\")\n",
    "all_final_preds10[\"kategori_adi\"] = all_final_preds10[\"kategori_adi\"].str.replace(\"'\", \"\")\n",
    "all_final_preds10[\"marka_adi\"] = all_final_preds10[\"marka_adi\"].str.replace(\"'\", \"\")\n",
    "all_final_preds10[\"urun_adi\"] = all_final_preds10[\"urun_adi\"].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_v6[\"indirim__bins\"] = df_all_v6[\"indirim__\"].apply(lambda x: 0 if x <= 0 else \n",
    "                                                          (1 if x <= 0.01 else \n",
    "                                                           (2 if x <= 0.02 else \n",
    "                                                            (3 if x <= 0.03 else \n",
    "                                                             (4 if x <= 0.04 else \n",
    "                                                              (5 if x <= 0.05 else \n",
    "                                                               (6 if x <= 0.06 else \n",
    "                                                                (7 if x <= 0.07 else \n",
    "                                                                 (8 if x <= 0.08 else \n",
    "                                                                  (9 if x <= 0.09 else \n",
    "                                                                   (10 if x <= 0.10 else \n",
    "                                                                    (12.5 if x <= 0.15 else 15))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463320, 28)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds10.shape\n",
    "#bir önceki iteration'da 443460 satır idi neden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"aktivite_etkisi\"] = np.nan\n",
    "for idx in grup_and_sku_list.index:\n",
    "    akt = df_all[(df_all[\"grup_adi\"] == grup_and_sku_list[\"grup_adi\"][idx]) & \n",
    "                 (df_all[\"en_guncel_kod\"] == grup_and_sku_list[\"en_guncel_kod\"][idx])][\"aktivite_tipi\"].unique()\n",
    "    \n",
    "    ind = df_all_v6[(df_all_v6[\"grup_adi\"] == grup_and_sku_list[\"grup_adi\"][idx]) & \n",
    "                    (df_all_v6[\"en_guncel_kod\"] == grup_and_sku_list[\"en_guncel_kod\"][idx])][\"indirim__bins\"].unique()\n",
    "    \n",
    "    indexes = all_final_preds10[(all_final_preds10[\"grup_adi\"] == grup_and_sku_list[\"grup_adi\"][idx]) & \n",
    "                                (all_final_preds10[\"en_guncel_kod\"] == grup_and_sku_list[\"en_guncel_kod\"][idx])].index\n",
    "    \n",
    "    if (len(akt) == 1 and len(ind) == 1) and (akt[0] == 0 and ind[0] == 0):\n",
    "        all_final_preds10.loc[list(indexes), \"aktivite_etkisi\"] = \"Yok\"\n",
    "    else:\n",
    "        all_final_preds10.loc[list(indexes), \"aktivite_etkisi\"] = \"Var\"\n",
    "all_final_preds10.aktivite_etkisi.fillna(\"Var\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463320, 29)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds10.shape #(443460, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_final_preds10.drop(columns=\"from\", axis=1, inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"en_guncel_kod\"] = all_final_preds10[\"en_guncel_kod\"].apply(lambda x: int(x) if \"T\" not in str(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_guncel_kod</th>\n",
       "      <th>grup_adi</th>\n",
       "      <th>tahmin_koli</th>\n",
       "      <th>mape</th>\n",
       "      <th>tahmin_edilme_yontemi</th>\n",
       "      <th>date</th>\n",
       "      <th>aktivite_tipi</th>\n",
       "      <th>indirim_yuzdesi</th>\n",
       "      <th>gerceklesen_satis_adedi</th>\n",
       "      <th>gerceklesen_koli</th>\n",
       "      <th>tahmin_sapmasi</th>\n",
       "      <th>Kanal</th>\n",
       "      <th>ana_kategori_adi</th>\n",
       "      <th>kategori_adi</th>\n",
       "      <th>marka_adi</th>\n",
       "      <th>tahmin_koli_alt_sinir</th>\n",
       "      <th>tahmin_koli_ust_sinir</th>\n",
       "      <th>tl_unit</th>\n",
       "      <th>tl</th>\n",
       "      <th>kg_unit</th>\n",
       "      <th>kg</th>\n",
       "      <th>koli_ici_adet</th>\n",
       "      <th>tahmin_adet</th>\n",
       "      <th>tahmin_ust_sinir</th>\n",
       "      <th>tahmin_alt_sinir</th>\n",
       "      <th>urun_adi</th>\n",
       "      <th>datanin_etiketlendigi_algorit</th>\n",
       "      <th>aktivite_etkisi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107701</td>\n",
       "      <td>A101</td>\n",
       "      <td>29868.906573</td>\n",
       "      <td>31.852574</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>Kasiyer</td>\n",
       "      <td>%3 - %4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>BİSKÜVİ</td>\n",
       "      <td>İKRAM</td>\n",
       "      <td>20354.890945</td>\n",
       "      <td>39382.922200</td>\n",
       "      <td>88.92</td>\n",
       "      <td>2.655943e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29868.906573</td>\n",
       "      <td>12.0</td>\n",
       "      <td>358426.878873</td>\n",
       "      <td>472595.066401</td>\n",
       "      <td>244258.691344</td>\n",
       "      <td>İKRAM KRE.BİSK.ÇİK.3x84Gx12</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>Var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107701</td>\n",
       "      <td>A101</td>\n",
       "      <td>21461.742583</td>\n",
       "      <td>31.852574</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>Çoklu Alım</td>\n",
       "      <td>%8 - %9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>BİSKÜVİ</td>\n",
       "      <td>İKRAM</td>\n",
       "      <td>14625.625103</td>\n",
       "      <td>28297.860063</td>\n",
       "      <td>88.92</td>\n",
       "      <td>1.908378e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21461.742583</td>\n",
       "      <td>12.0</td>\n",
       "      <td>257540.910999</td>\n",
       "      <td>339574.320757</td>\n",
       "      <td>175507.501240</td>\n",
       "      <td>İKRAM KRE.BİSK.ÇİK.3x84Gx12</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>Var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107701</td>\n",
       "      <td>A101</td>\n",
       "      <td>23793.070111</td>\n",
       "      <td>31.852574</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>Mağaza içi/Dağılım</td>\n",
       "      <td>%4 - %5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>BİSKÜVİ</td>\n",
       "      <td>İKRAM</td>\n",
       "      <td>16214.364801</td>\n",
       "      <td>31371.775422</td>\n",
       "      <td>88.92</td>\n",
       "      <td>2.115680e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23793.070111</td>\n",
       "      <td>12.0</td>\n",
       "      <td>285516.841337</td>\n",
       "      <td>376461.305064</td>\n",
       "      <td>194572.377610</td>\n",
       "      <td>İKRAM KRE.BİSK.ÇİK.3x84Gx12</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>Var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107701</td>\n",
       "      <td>A101</td>\n",
       "      <td>23556.143584</td>\n",
       "      <td>31.852574</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>Kasiyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>BİSKÜVİ</td>\n",
       "      <td>İKRAM</td>\n",
       "      <td>16052.905471</td>\n",
       "      <td>31059.381696</td>\n",
       "      <td>88.92</td>\n",
       "      <td>2.094612e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23556.143584</td>\n",
       "      <td>12.0</td>\n",
       "      <td>282673.723005</td>\n",
       "      <td>372712.580356</td>\n",
       "      <td>192634.865654</td>\n",
       "      <td>İKRAM KRE.BİSK.ÇİK.3x84Gx12</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>Var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107701</td>\n",
       "      <td>A101</td>\n",
       "      <td>34247.099222</td>\n",
       "      <td>31.852574</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>Kasiyer</td>\n",
       "      <td>%6 - %7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pasifik</td>\n",
       "      <td>ATIŞTIRMALIK</td>\n",
       "      <td>BİSKÜVİ</td>\n",
       "      <td>İKRAM</td>\n",
       "      <td>23338.516532</td>\n",
       "      <td>45155.681911</td>\n",
       "      <td>88.92</td>\n",
       "      <td>3.045252e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34247.099222</td>\n",
       "      <td>12.0</td>\n",
       "      <td>410965.190658</td>\n",
       "      <td>541868.182929</td>\n",
       "      <td>280062.198387</td>\n",
       "      <td>İKRAM KRE.BİSK.ÇİK.3x84Gx12</td>\n",
       "      <td>DIAG1_UCM1</td>\n",
       "      <td>Var</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  en_guncel_kod grup_adi   tahmin_koli       mape tahmin_edilme_yontemi  \\\n",
       "0        107701     A101  29868.906573  31.852574            DIAG1_UCM1   \n",
       "1        107701     A101  21461.742583  31.852574            DIAG1_UCM1   \n",
       "2        107701     A101  23793.070111  31.852574            DIAG1_UCM1   \n",
       "3        107701     A101  23556.143584  31.852574            DIAG1_UCM1   \n",
       "4        107701     A101  34247.099222  31.852574            DIAG1_UCM1   \n",
       "\n",
       "        date       aktivite_tipi indirim_yuzdesi  gerceklesen_satis_adedi  \\\n",
       "0 2022-03-01             Kasiyer         %3 - %4                        0   \n",
       "1 2022-04-01          Çoklu Alım         %8 - %9                        0   \n",
       "2 2022-03-01  Mağaza içi/Dağılım         %4 - %5                        0   \n",
       "3 2022-06-01             Kasiyer               0                        0   \n",
       "4 2022-03-01             Kasiyer         %6 - %7                        0   \n",
       "\n",
       "   gerceklesen_koli  tahmin_sapmasi    Kanal ana_kategori_adi kategori_adi  \\\n",
       "0                 0               0  pasifik     ATIŞTIRMALIK      BİSKÜVİ   \n",
       "1                 0               0  pasifik     ATIŞTIRMALIK      BİSKÜVİ   \n",
       "2                 0               0  pasifik     ATIŞTIRMALIK      BİSKÜVİ   \n",
       "3                 0               0  pasifik     ATIŞTIRMALIK      BİSKÜVİ   \n",
       "4                 0               0  pasifik     ATIŞTIRMALIK      BİSKÜVİ   \n",
       "\n",
       "  marka_adi  tahmin_koli_alt_sinir  tahmin_koli_ust_sinir  tl_unit  \\\n",
       "0     İKRAM           20354.890945           39382.922200    88.92   \n",
       "1     İKRAM           14625.625103           28297.860063    88.92   \n",
       "2     İKRAM           16214.364801           31371.775422    88.92   \n",
       "3     İKRAM           16052.905471           31059.381696    88.92   \n",
       "4     İKRAM           23338.516532           45155.681911    88.92   \n",
       "\n",
       "             tl  kg_unit            kg  koli_ici_adet    tahmin_adet  \\\n",
       "0  2.655943e+06      1.0  29868.906573           12.0  358426.878873   \n",
       "1  1.908378e+06      1.0  21461.742583           12.0  257540.910999   \n",
       "2  2.115680e+06      1.0  23793.070111           12.0  285516.841337   \n",
       "3  2.094612e+06      1.0  23556.143584           12.0  282673.723005   \n",
       "4  3.045252e+06      1.0  34247.099222           12.0  410965.190658   \n",
       "\n",
       "   tahmin_ust_sinir  tahmin_alt_sinir                     urun_adi  \\\n",
       "0     472595.066401     244258.691344  İKRAM KRE.BİSK.ÇİK.3x84Gx12   \n",
       "1     339574.320757     175507.501240  İKRAM KRE.BİSK.ÇİK.3x84Gx12   \n",
       "2     376461.305064     194572.377610  İKRAM KRE.BİSK.ÇİK.3x84Gx12   \n",
       "3     372712.580356     192634.865654  İKRAM KRE.BİSK.ÇİK.3x84Gx12   \n",
       "4     541868.182929     280062.198387  İKRAM KRE.BİSK.ÇİK.3x84Gx12   \n",
       "\n",
       "  datanin_etiketlendigi_algorit aktivite_etkisi  \n",
       "0                    DIAG1_UCM1             Var  \n",
       "1                    DIAG1_UCM1             Var  \n",
       "2                    DIAG1_UCM1             Var  \n",
       "3                    DIAG1_UCM1             Var  \n",
       "4                    DIAG1_UCM1             Var  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10.rename(columns=col_name_dwh, inplace=True)\n",
    "all_final_preds10 = all_final_preds10[col_name_dwh_order]\n",
    "\n",
    "kanal_order = {'pasifik': 'PASİFİK', \n",
    "               'btt': 'BTT', \n",
    "               'horizon': 'HORİZON'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pasifik', 'btt', 'horizon'], dtype=object)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_final_preds10.KANAL.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kanal isimlerini kanal_order dictionary'sindeki haline getiriyorum ve indirim yüzdesinde integer varsa stringe çeviriyorum\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"KANAL\"] = all_final_preds10[\"KANAL\"].map(kanal_order)\n",
    "all_final_preds10[\"INDIRIM_YUZDESI\"] = all_final_preds10[\"INDIRIM_YUZDESI\"].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ne olur ne olmaz diye drop duplicates yapıyorum tekrarlayan satırlar olmasın diye\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10.drop_duplicates(ignore_index=True, inplace=True)\n",
    "all_final_preds10_backup = all_final_preds10.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kg hesabı yaparken tahmin koli ile bir kolinin ağırlığını çarpıyorum\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"KG\"] = all_final_preds10[\"TAHMIN_KOLI\"] * all_final_preds10[\"KG_UNIT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tahminin kilo karşılığını getirirken virgülden sonra 3 hane, tl için virgülden sonra 2 hane bırakıyorum. tahminleri de yukarıya yuvarlıyorum. Mesela 155.56 ise 156 oluyor\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds10[\"KG\"] = np.round(all_final_preds10[\"KG\"], 3)\n",
    "all_final_preds10[\"TL\"] = np.round(all_final_preds10[\"TL\"], 2)\n",
    "all_final_preds10[\"TAHMIN_KOLI\"] = np.ceil(all_final_preds10[\"TAHMIN_KOLI\"])\n",
    "all_final_preds10[\"TAHMIN_KOLI_ALT_SINIR\"] = np.ceil(all_final_preds10[\"TAHMIN_KOLI_ALT_SINIR\"])\n",
    "all_final_preds10[\"TAHMIN_KOLI_UST_SINIR\"] = np.ceil(all_final_preds10[\"TAHMIN_KOLI_UST_SINIR\"])\n",
    "all_final_preds10[\"TARIH\"] = all_final_preds10[\"TARIH\"].astype(str)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def connect_to_oracle_exadata(): \n",
    "\n",
    "    #to fect data \n",
    "\n",
    "    connstr = 'USER_BTS/USER_BTS!!58d*v.f@mbsbo-scan1:1521/YBO' \n",
    "\n",
    "    conn = cx_Oracle.connect(connstr,encoding='UTF-8', nencoding='UTF-8') \n",
    "\n",
    "    #to upload data \n",
    "\n",
    "    conn_oracle = create_engine('oracle+cx_oracle://USER_BTS:USER_BTS!!58d*v.f@mbsbo-scan1:1521/?service_name=YBO',  \n",
    "\n",
    "                                connect_args={\"encoding\": \"UTF-8\", \"nencoding\": \"UTF-8\" } \n",
    "\n",
    "                                ) \n",
    "\n",
    "     \n",
    "\n",
    "    #close connection by type --> conn.close() after the use. \n",
    "\n",
    "    return conn, conn_oracle "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def connect_to_oracle_exadata_dwhtest(): \n",
    "\n",
    "    #to fect data \n",
    "\n",
    "    connstr = 'DWHTEST_READ/DwhT357dtY3@mbsbo-scan1:1521/YBO' \n",
    "\n",
    "    conn = cx_Oracle.connect(connstr,encoding='UTF-8', nencoding='UTF-8') \n",
    "\n",
    "    #to upload data \n",
    "\n",
    "    conn_oracle = create_engine('oracle+cx_oracle://DWHTEST_READ:DwhT357dtY3@mbsbo-scan1:1521/?service_name=YBO', \n",
    "\n",
    "                                connect_args={\"encoding\": \"UTF-8\", \"nencoding\": \"UTF-8\" } \n",
    "\n",
    "                                ) \n",
    "\n",
    "  \n",
    "\n",
    "    #close connection by type --> conn.close() after the use. \n",
    "\n",
    "    return conn, conn_oracle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizon için de aktivite girilmişse çıkartmak amacıyla yazdım aşağıdakini\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_final_preds11 = all_final_preds10[~((all_final_preds10[\"KANAL\"].isin([\"HORİZON\", \"BTT\"])) & (all_final_preds10[\"AKTIVITE_TIPI\"] != \"Yok\"))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape'leri kontrol etmek için yazdım\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWAT bağlantısı koptu. Bağlantı tekrar kuruluyor.\n",
      "Bağlantı kuruldu!\n",
      "NOTE: Cloud Analytic Services dropped table DEMAND_SENSING_RESULTS from caslib DSENS_P.\n",
      "NOTE: Cloud Analytic Services made the uploaded file available as table DEMAND_SENSING_RESULTS in caslib DSENS_P.\n",
      "NOTE: The table DEMAND_SENSING_RESULTS has been created in caslib DSENS_P from binary data uploaded to Cloud Analytic Services.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"cas-results-key\"><b>&#167; caslib</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>DSENS_P</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; tableName</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>DEMAND_SENSING_RESULTS</div>\n",
       "</div>\n",
       "<div class=\"cas-results-key\"><hr/><b>&#167; casTable</b></div>\n",
       "<div class=\"cas-results-body\">\n",
       "<div>CASTable('DEMAND_SENSING_RESULTS', caslib='DSENS_P')</div>\n",
       "</div>\n",
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 200s</span> &#183; <span class=\"cas-user\">user 4.52s</span> &#183; <span class=\"cas-sys\">sys 1.69s</span> &#183; <span class=\"cas-memory\">mem 85.5MB</span></small></p>"
      ],
      "text/plain": [
       "[caslib]\n",
       "\n",
       " 'DSENS_P'\n",
       "\n",
       "[tableName]\n",
       "\n",
       " 'DEMAND_SENSING_RESULTS'\n",
       "\n",
       "[casTable]\n",
       "\n",
       " CASTable('DEMAND_SENSING_RESULTS', caslib='DSENS_P')\n",
       "\n",
       "+ Elapsed: 200s, user: 4.52s, sys: 1.69s, mem: 85.5mb"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: \n",
    "    conn.userinfo()\n",
    "except: \n",
    "    print(\"SWAT bağlantısı koptu. Bağlantı tekrar kuruluyor.\")\n",
    "    access_ = True\n",
    "    while access_:\n",
    "        try:\n",
    "            conn = swat.CAS('yhtrcl-sasccnt1.yildiz.domain', 5570, username=params_[\"login_info\"][\"username\"], password=params_[\"login_info\"][\"password\"])\n",
    "            access_ = False\n",
    "            print(\"Bağlantı kuruldu!\")\n",
    "        except:\n",
    "            print(\"Beklenmedik bir hata oluştu. Bağlantı tekrar kuruluyor...\")\n",
    "            continue\n",
    "#ds_table = conn.CASTable(\"DEMAND_SENSING_RESULTS\", caslib=params_[\"caslib_info\"][\"caslib_name\"], replace=True)\n",
    "#ds_table.table.dropTable(quiet=True)\n",
    "if conn.table.tableExists(name=\"DEMAND_SENSING_RESULTS\",caslib=params_['caslib_info']['caslib_name']).exists:\n",
    "    conn.table.dropTable(name=\"DEMAND_SENSING_RESULTS\",caslib=params_['caslib_info']['caslib_name'])\n",
    "conn.upload(data=all_final_preds11, \n",
    "            casout={'caslib':params_[\"caslib_info\"][\"caslib_name\"], 'name':\"DEMAND_SENSING_RESULTS\", 'promote':True})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_final_preds10.to_excel(\"../results/ocak_tum_sonuclar.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_final_preds11.to_excel(f\"../results/{data_name_dict[ay_threshold+1]}_tum_sonuclar.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_all_v6.to_excel(\"../data/historic_data_\"+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_\"+str(params_[\"time_info_for_debugging\"][\"yil\"])+\".xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeli_export = df_all_v6[[\"Kanal\", \"grup_adi\", \"en_guncel_kod\", \"portfoy\", \"durum\"]]\n",
    "listeli_export = listeli_export[listeli_export[\"Kanal\"] == \"pasifik\"]\n",
    "listeli_export.drop(\"Kanal\", axis=1, inplace=True)\n",
    "listeli_export.drop_duplicates(ignore_index=False, inplace=True)\n",
    "listeli_export.to_excel(\"../data/listeli_urun_listesi_\"+data_name_dict[params_[\"time_info_for_debugging\"][\"ay\"]]+\"_\"+str(params_[\"time_info_for_debugging\"][\"yil\"])+\".xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "chng_names = {\"KANAL\": \"Kanal\", \n",
    "              \"GRUP_ADI\": \"Grup Adı\", \n",
    "              \"ANA_KATEGORI_ADI\": \"Ana Kategori\",\n",
    "              \"KATEGORI_ADI\": \"Kategori\", \n",
    "              \"MARKA_ADI\": \"Marka\", \n",
    "              \"URUN_ADI\": \"Ürün Adı\", \n",
    "              \"EN_GUNCEL_KOD\": \"Ürün Kodu\"}\n",
    "\n",
    "all_possile_selections = all_final_preds11[[\"KANAL\", \"GRUP_ADI\", \"ANA_KATEGORI_ADI\", \"KATEGORI_ADI\", \"MARKA_ADI\", \"URUN_ADI\", \"EN_GUNCEL_KOD\"]]\n",
    "all_possile_selections.drop_duplicates(ignore_index=True, inplace=True)\n",
    "all_possile_selections.rename(columns=chng_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possile_selections.to_excel(\"../data/__all_possible_selections.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"../data/historic_data_for_graph.csv\", index=False)\n",
    "df_all_v6.to_csv(\"../data/historic_data_trend_for_graph.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Geçmiş ve güncel predictionların database'e yazılması\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_upload = all_final_preds11.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_upload[\"DATANIN_KESILDIGI_TARIH\"] = datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)\n",
    "database_upload[\"TAHMINLENEN_TARIH\"] = t_2_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sas_upload[\"datanin_kesildigi_tarih\"] = datetime(params_[\"time_info_for_debugging\"][\"yil\"], params_[\"time_info_for_debugging\"][\"ay\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data is inserted into DS_HISTORY_RESULTS table.\n",
      "New data is inserted into DS_HISTORY_DATA table.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "#    create_connection(r\"../data/db/\"+params_[\"db_info\"][\"db_name\"]+\".sqlite\") # creates new database if there is no db.\n",
    "#    create_new_table(all_final_preds11, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"current_results_table\"]) # creates new table if there is no table.\n",
    "#    upload_new_results(all_final_preds11, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"current_results_table\"]) # drop previous predictions and uploads new predictions for current period.\n",
    "    \n",
    "    update_table(database_upload, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"history_results_table\"]) # inserts to backup database.\n",
    "#    update_table(df_sas_upload, params_[\"db_info\"][\"db_name\"], params_[\"db_info\"][\"historic_data\"]) # inserts to historic database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/db/DS_DATABASE.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_sql_query(\"SELECT * FROM DS_HISTORY_RESULTS\", con=conn)\n",
    "b = pd.read_sql_query(\"SELECT * FROM DS_HISTORY_DATA\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
